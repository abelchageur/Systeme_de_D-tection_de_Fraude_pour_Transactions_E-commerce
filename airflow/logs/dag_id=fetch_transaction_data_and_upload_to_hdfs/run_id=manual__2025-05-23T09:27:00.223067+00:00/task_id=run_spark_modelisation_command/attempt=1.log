[2025-05-23T09:27:11.313+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_transaction_data_and_upload_to_hdfs.run_spark_modelisation_command manual__2025-05-23T09:27:00.223067+00:00 [queued]>
[2025-05-23T09:27:11.323+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_transaction_data_and_upload_to_hdfs.run_spark_modelisation_command manual__2025-05-23T09:27:00.223067+00:00 [queued]>
[2025-05-23T09:27:11.324+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 2
[2025-05-23T09:27:11.340+0000] {taskinstance.py:1382} INFO - Executing <Task(BashOperator): run_spark_modelisation_command> on 2025-05-23 09:27:00.223067+00:00
[2025-05-23T09:27:11.347+0000] {standard_task_runner.py:57} INFO - Started process 483 to run task
[2025-05-23T09:27:11.350+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'fetch_transaction_data_and_upload_to_hdfs', 'run_spark_modelisation_command', 'manual__2025-05-23T09:27:00.223067+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/ETL.py', '--cfg-path', '/tmp/tmpa0q5vtn_']
[2025-05-23T09:27:11.353+0000] {standard_task_runner.py:85} INFO - Job 15: Subtask run_spark_modelisation_command
[2025-05-23T09:27:11.408+0000] {task_command.py:415} INFO - Running <TaskInstance: fetch_transaction_data_and_upload_to_hdfs.run_spark_modelisation_command manual__2025-05-23T09:27:00.223067+00:00 [running]> on host 6c702459c558
[2025-05-23T09:27:11.727+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_transaction_data_and_upload_to_hdfs' AIRFLOW_CTX_TASK_ID='run_spark_modelisation_command' AIRFLOW_CTX_EXECUTION_DATE='2025-05-23T09:27:00.223067+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-23T09:27:00.223067+00:00'
[2025-05-23T09:27:11.729+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-05-23T09:27:11.731+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'docker exec spark-master python3 modelisation.py']
[2025-05-23T09:27:11.743+0000] {subprocess.py:86} INFO - Output:
[2025-05-23T09:27:14.440+0000] {subprocess.py:93} INFO - Setting default log level to "WARN".
[2025-05-23T09:27:14.441+0000] {subprocess.py:93} INFO - To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[2025-05-23T09:27:14.751+0000] {subprocess.py:93} INFO - 25/05/23 09:27:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-23T09:27:20.891+0000] {subprocess.py:93} INFO - [Stage 0:>                                                          (0 + 1) / 1]25/05/23 09:27:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.
[2025-05-23T09:27:20.892+0000] {subprocess.py:93} INFO -  Header: Transaction ID, Customer ID, Transaction Amount, Transaction Date, Payment Method, Product Category, Quantity, Customer Age, Customer Location, Device Used, IP Address, Shipping Address, Billing Address, Is Fraudulent, Account Age Days, Transaction Hour
[2025-05-23T09:27:20.892+0000] {subprocess.py:93} INFO -  Schema: Transaction_ID, Customer_ID, Transaction_Amount, Transaction_Date, Payment_Method, Product_Category, Quantity, Customer_Age, Customer_Location, Device_Used, IP_Address, Shipping_Address, Billing_Address, Is_Fraudulent, Account_Age_Days, Transaction_Hour
[2025-05-23T09:27:20.893+0000] {subprocess.py:93} INFO - Expected: Transaction_ID but found: Transaction ID
[2025-05-23T09:27:20.894+0000] {subprocess.py:93} INFO - CSV file: hdfs://namenode:9000/user/root/transactions/YYYY=2025/MM=05/DD=23/transaction_data.csv
[2025-05-23T09:27:23.308+0000] {subprocess.py:93} INFO -                                                                                 25/05/23 09:27:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.
[2025-05-23T09:27:23.309+0000] {subprocess.py:93} INFO -  Header: Transaction ID, Customer ID, Transaction Amount, Transaction Date, Payment Method, Product Category, Quantity, Customer Age, Customer Location, Device Used, IP Address, Shipping Address, Billing Address, Is Fraudulent, Account Age Days, Transaction Hour
[2025-05-23T09:27:23.310+0000] {subprocess.py:93} INFO -  Schema: Transaction_ID, Customer_ID, Transaction_Amount, Transaction_Date, Payment_Method, Product_Category, Quantity, Customer_Age, Customer_Location, Device_Used, IP_Address, Shipping_Address, Billing_Address, Is_Fraudulent, Account_Age_Days, Transaction_Hour
[2025-05-23T09:27:23.310+0000] {subprocess.py:93} INFO - Expected: Transaction_ID but found: Transaction ID
[2025-05-23T09:27:23.311+0000] {subprocess.py:93} INFO - CSV file: hdfs://namenode:9000/user/root/transactions/YYYY=2025/MM=05/DD=23/transaction_data.csv
[2025-05-23T09:27:23.431+0000] {subprocess.py:93} INFO - 25/05/23 09:27:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.
[2025-05-23T09:27:23.433+0000] {subprocess.py:93} INFO -  Header: Transaction ID, Customer ID, Transaction Amount, Transaction Date, Payment Method, Product Category, Quantity, Customer Age, Customer Location, Device Used, IP Address, Shipping Address, Billing Address, Is Fraudulent, Account Age Days, Transaction Hour
[2025-05-23T09:27:23.434+0000] {subprocess.py:93} INFO -  Schema: Transaction_ID, Customer_ID, Transaction_Amount, Transaction_Date, Payment_Method, Product_Category, Quantity, Customer_Age, Customer_Location, Device_Used, IP_Address, Shipping_Address, Billing_Address, Is_Fraudulent, Account_Age_Days, Transaction_Hour
[2025-05-23T09:27:23.436+0000] {subprocess.py:93} INFO - Expected: Transaction_ID but found: Transaction ID
[2025-05-23T09:27:23.438+0000] {subprocess.py:93} INFO - CSV file: hdfs://namenode:9000/user/root/transactions/YYYY=2025/MM=05/DD=23/transaction_data.csv
[2025-05-23T09:27:23.673+0000] {subprocess.py:93} INFO - [Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 4:>                  (0 + 1) / 1]25/05/23 09:27:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.
[2025-05-23T09:27:23.675+0000] {subprocess.py:93} INFO -  Header: Transaction ID, Customer ID, Transaction Amount, Transaction Date, Payment Method, Product Category, Quantity, Customer Age, Customer Location, Device Used, IP Address, Shipping Address, Billing Address, Is Fraudulent, Account Age Days, Transaction Hour
[2025-05-23T09:27:23.675+0000] {subprocess.py:93} INFO -  Schema: Transaction_ID, Customer_ID, Transaction_Amount, Transaction_Date, Payment_Method, Product_Category, Quantity, Customer_Age, Customer_Location, Device_Used, IP_Address, Shipping_Address, Billing_Address, Is_Fraudulent, Account_Age_Days, Transaction_Hour
[2025-05-23T09:27:23.676+0000] {subprocess.py:93} INFO - Expected: Transaction_ID but found: Transaction ID
[2025-05-23T09:27:23.677+0000] {subprocess.py:93} INFO - CSV file: hdfs://namenode:9000/user/root/transactions/YYYY=2025/MM=05/DD=23/transaction_data.csv
[2025-05-23T09:27:24.918+0000] {subprocess.py:93} INFO -                                                                                 25/05/23 09:27:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.
[2025-05-23T09:27:24.919+0000] {subprocess.py:93} INFO -  Header: Transaction ID, Customer ID, Transaction Amount, Transaction Date, Payment Method, Product Category, Quantity, Customer Age, Customer Location, Device Used, IP Address, Shipping Address, Billing Address, Is Fraudulent, Account Age Days, Transaction Hour
[2025-05-23T09:27:24.921+0000] {subprocess.py:93} INFO -  Schema: Transaction_ID, Customer_ID, Transaction_Amount, Transaction_Date, Payment_Method, Product_Category, Quantity, Customer_Age, Customer_Location, Device_Used, IP_Address, Shipping_Address, Billing_Address, Is_Fraudulent, Account_Age_Days, Transaction_Hour
[2025-05-23T09:27:24.922+0000] {subprocess.py:93} INFO - Expected: Transaction_ID but found: Transaction ID
[2025-05-23T09:27:24.923+0000] {subprocess.py:93} INFO - CSV file: hdfs://namenode:9000/user/root/transactions/YYYY=2025/MM=05/DD=23/transaction_data.csv
[2025-05-23T09:27:27.670+0000] {subprocess.py:93} INFO - [Stage 12:>                                                         (0 + 1) / 1]                                                                                [Stage 13:>                                                         (0 + 1) / 1]25/05/23 09:27:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.
[2025-05-23T09:27:27.672+0000] {subprocess.py:93} INFO -  Header: Transaction ID, Customer ID, Transaction Amount, Transaction Date, Payment Method, Product Category, Quantity, Customer Age, Customer Location, Device Used, IP Address, Shipping Address, Billing Address, Is Fraudulent, Account Age Days, Transaction Hour
[2025-05-23T09:27:27.673+0000] {subprocess.py:93} INFO -  Schema: Transaction_ID, Customer_ID, Transaction_Amount, Transaction_Date, Payment_Method, Product_Category, Quantity, Customer_Age, Customer_Location, Device_Used, IP_Address, Shipping_Address, Billing_Address, Is_Fraudulent, Account_Age_Days, Transaction_Hour
[2025-05-23T09:27:27.674+0000] {subprocess.py:93} INFO - Expected: Transaction_ID but found: Transaction ID
[2025-05-23T09:27:27.674+0000] {subprocess.py:93} INFO - CSV file: hdfs://namenode:9000/user/root/transactions/YYYY=2025/MM=05/DD=23/transaction_data.csv
[2025-05-23T09:27:29.293+0000] {subprocess.py:93} INFO - [Stage 15:>                                                         (0 + 1) / 1]                                                                                25/05/23 09:27:29 WARN CSVHeaderChecker: CSV header does not conform to the schema.
[2025-05-23T09:27:29.294+0000] {subprocess.py:93} INFO -  Header: Transaction ID, Customer ID, Transaction Amount, Transaction Date, Payment Method, Product Category, Quantity, Customer Age, Customer Location, Device Used, IP Address, Shipping Address, Billing Address, Is Fraudulent, Account Age Days, Transaction Hour
[2025-05-23T09:27:29.295+0000] {subprocess.py:93} INFO -  Schema: Transaction_ID, Customer_ID, Transaction_Amount, Transaction_Date, Payment_Method, Product_Category, Quantity, Customer_Age, Customer_Location, Device_Used, IP_Address, Shipping_Address, Billing_Address, Is_Fraudulent, Account_Age_Days, Transaction_Hour
[2025-05-23T09:27:29.296+0000] {subprocess.py:93} INFO - Expected: Transaction_ID but found: Transaction ID
[2025-05-23T09:27:29.296+0000] {subprocess.py:93} INFO - CSV file: hdfs://namenode:9000/user/root/transactions/YYYY=2025/MM=05/DD=23/transaction_data.csv
[2025-05-23T09:27:29.853+0000] {subprocess.py:93} INFO - 25/05/23 09:27:29 WARN CSVHeaderChecker: CSV header does not conform to the schema.
[2025-05-23T09:27:29.854+0000] {subprocess.py:93} INFO -  Header: Transaction ID, Customer ID, Transaction Amount, Transaction Date, Payment Method, Product Category, Quantity, Customer Age, Customer Location, Device Used, IP Address, Shipping Address, Billing Address, Is Fraudulent, Account Age Days, Transaction Hour
[2025-05-23T09:27:29.854+0000] {subprocess.py:93} INFO -  Schema: Transaction_ID, Customer_ID, Transaction_Amount, Transaction_Date, Payment_Method, Product_Category, Quantity, Customer_Age, Customer_Location, Device_Used, IP_Address, Shipping_Address, Billing_Address, Is_Fraudulent, Account_Age_Days, Transaction_Hour
[2025-05-23T09:27:29.855+0000] {subprocess.py:93} INFO - Expected: Transaction_ID but found: Transaction ID
[2025-05-23T09:27:29.856+0000] {subprocess.py:93} INFO - CSV file: hdfs://namenode:9000/user/root/transactions/YYYY=2025/MM=05/DD=23/transaction_data.csv
[2025-05-23T09:27:30.626+0000] {subprocess.py:93} INFO - 25/05/23 09:27:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.
[2025-05-23T09:27:30.627+0000] {subprocess.py:93} INFO -  Header: Transaction ID, Customer ID, Transaction Amount, Transaction Date, Payment Method, Product Category, Quantity, Customer Age, Customer Location, Device Used, IP Address, Shipping Address, Billing Address, Is Fraudulent, Account Age Days, Transaction Hour
[2025-05-23T09:27:30.628+0000] {subprocess.py:93} INFO -  Schema: Transaction_ID, Customer_ID, Transaction_Amount, Transaction_Date, Payment_Method, Product_Category, Quantity, Customer_Age, Customer_Location, Device_Used, IP_Address, Shipping_Address, Billing_Address, Is_Fraudulent, Account_Age_Days, Transaction_Hour
[2025-05-23T09:27:30.629+0000] {subprocess.py:93} INFO - Expected: Transaction_ID but found: Transaction ID
[2025-05-23T09:27:30.629+0000] {subprocess.py:93} INFO - CSV file: hdfs://namenode:9000/user/root/transactions/YYYY=2025/MM=05/DD=23/transaction_data.csv
[2025-05-23T09:27:31.341+0000] {subprocess.py:93} INFO - 25/05/23 09:27:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.
[2025-05-23T09:27:31.342+0000] {subprocess.py:93} INFO -  Header: Transaction ID, Customer ID, Transaction Amount, Transaction Date, Payment Method, Product Category, Quantity, Customer Age, Customer Location, Device Used, IP Address, Shipping Address, Billing Address, Is Fraudulent, Account Age Days, Transaction Hour
[2025-05-23T09:27:31.342+0000] {subprocess.py:93} INFO -  Schema: Transaction_ID, Customer_ID, Transaction_Amount, Transaction_Date, Payment_Method, Product_Category, Quantity, Customer_Age, Customer_Location, Device_Used, IP_Address, Shipping_Address, Billing_Address, Is_Fraudulent, Account_Age_Days, Transaction_Hour
[2025-05-23T09:27:31.343+0000] {subprocess.py:93} INFO - Expected: Transaction_ID but found: Transaction ID
[2025-05-23T09:27:31.344+0000] {subprocess.py:93} INFO - CSV file: hdfs://namenode:9000/user/root/transactions/YYYY=2025/MM=05/DD=23/transaction_data.csv
[2025-05-23T09:27:33.100+0000] {subprocess.py:93} INFO - Spark session created successfully!
[2025-05-23T09:27:33.101+0000] {subprocess.py:93} INFO - Data loaded successfully. Row count: 23634
[2025-05-23T09:27:33.102+0000] {subprocess.py:93} INFO - Data saved to HDFS successfully!
[2025-05-23T09:27:33.551+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-05-23T09:27:33.578+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=fetch_transaction_data_and_upload_to_hdfs, task_id=run_spark_modelisation_command, execution_date=20250523T092700, start_date=20250523T092711, end_date=20250523T092733
[2025-05-23T09:27:33.623+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-05-23T09:27:33.655+0000] {taskinstance.py:2784} INFO - 1 downstream tasks scheduled from follow-on schedule check
