[2025-03-15T15:38:57.579+0000] {processor.py:157} INFO - Started process (PID=567) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:38:57.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:38:57.582+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:38:57.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:38:57.664+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:38:57.653+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:38:57.665+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:38:57.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.117 seconds
[2025-03-15T15:39:28.254+0000] {processor.py:157} INFO - Started process (PID=577) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:39:28.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:39:28.259+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:39:28.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:39:28.302+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:39:28.294+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:39:28.304+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:39:28.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.093 seconds
[2025-03-15T15:39:58.719+0000] {processor.py:157} INFO - Started process (PID=587) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:39:58.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:39:58.724+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:39:58.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:39:58.762+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:39:58.755+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:39:58.763+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:39:58.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.096 seconds
[2025-03-15T15:40:29.636+0000] {processor.py:157} INFO - Started process (PID=597) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:40:29.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:40:29.639+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:40:29.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:40:29.694+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:40:29.687+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:40:29.695+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:40:29.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.084 seconds
[2025-03-15T15:41:00.616+0000] {processor.py:157} INFO - Started process (PID=607) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:41:00.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:41:00.619+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:41:00.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:41:00.658+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:41:00.650+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:41:00.659+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:41:00.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.069 seconds
[2025-03-15T15:41:31.578+0000] {processor.py:157} INFO - Started process (PID=617) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:41:31.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:41:31.591+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:41:31.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:41:31.653+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:41:31.644+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:41:31.654+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:41:31.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.150 seconds
[2025-03-15T15:42:02.595+0000] {processor.py:157} INFO - Started process (PID=627) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:42:02.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:42:02.598+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:42:02.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:42:02.619+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:42:02.616+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:42:02.620+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:42:02.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T15:42:32.995+0000] {processor.py:157} INFO - Started process (PID=637) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:42:32.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:42:32.998+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:42:32.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:42:33.035+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:42:33.026+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:42:33.037+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:42:33.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.066 seconds
[2025-03-15T15:43:03.902+0000] {processor.py:157} INFO - Started process (PID=647) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:43:03.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:43:03.905+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:43:03.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:43:03.949+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:43:03.942+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:43:03.950+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:43:03.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.085 seconds
[2025-03-15T15:43:34.948+0000] {processor.py:157} INFO - Started process (PID=657) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:43:34.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:43:34.951+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:43:34.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:43:34.997+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:43:34.989+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:43:34.998+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:43:35.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.077 seconds
[2025-03-15T15:44:05.941+0000] {processor.py:157} INFO - Started process (PID=667) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:44:05.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:44:05.944+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:44:05.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:44:05.970+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:44:05.964+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:44:05.971+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:44:05.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.055 seconds
[2025-03-15T15:44:36.815+0000] {processor.py:157} INFO - Started process (PID=677) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:44:36.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:44:36.817+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:44:36.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:44:36.853+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:44:36.845+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:44:36.854+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:44:36.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.066 seconds
[2025-03-15T15:45:07.775+0000] {processor.py:157} INFO - Started process (PID=687) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:45:07.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:45:07.778+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:45:07.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:45:07.818+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:45:07.813+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:45:07.819+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:45:07.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.079 seconds
[2025-03-15T15:45:38.751+0000] {processor.py:157} INFO - Started process (PID=697) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:45:38.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:45:38.753+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:45:38.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:45:38.795+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:45:38.788+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:45:38.796+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:45:38.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.072 seconds
[2025-03-15T15:46:09.636+0000] {processor.py:157} INFO - Started process (PID=707) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:46:09.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:46:09.638+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:46:09.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:46:09.660+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:46:09.656+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:46:09.661+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:46:09.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T15:46:39.959+0000] {processor.py:157} INFO - Started process (PID=717) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:46:39.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:46:39.973+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:46:39.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:46:40.028+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:46:40.014+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:46:40.029+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:46:40.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.117 seconds
[2025-03-15T15:47:10.952+0000] {processor.py:157} INFO - Started process (PID=727) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:47:10.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:47:10.955+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:47:10.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:47:10.979+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:47:10.974+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:47:10.980+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:47:11.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.057 seconds
[2025-03-15T15:47:41.766+0000] {processor.py:157} INFO - Started process (PID=737) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:47:41.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:47:41.769+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:47:41.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:47:41.813+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:47:41.805+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:47:41.814+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:47:41.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.075 seconds
[2025-03-15T15:48:12.668+0000] {processor.py:157} INFO - Started process (PID=747) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:48:12.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:48:12.671+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:48:12.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:48:12.716+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:48:12.708+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:48:12.717+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:48:12.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.088 seconds
[2025-03-15T15:48:43.743+0000] {processor.py:157} INFO - Started process (PID=757) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:48:43.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:48:43.746+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:48:43.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:48:43.787+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:48:43.778+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:48:43.788+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:48:43.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.078 seconds
[2025-03-15T15:49:14.742+0000] {processor.py:157} INFO - Started process (PID=767) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:49:14.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:49:14.745+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:49:14.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:49:14.788+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:49:14.780+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:49:14.789+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:49:14.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.082 seconds
[2025-03-15T15:49:45.704+0000] {processor.py:157} INFO - Started process (PID=777) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:49:45.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:49:45.708+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:49:45.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:49:45.747+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:49:45.740+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:49:45.749+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:49:45.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.083 seconds
[2025-03-15T15:50:15.877+0000] {processor.py:157} INFO - Started process (PID=787) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:50:15.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:50:15.883+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:50:15.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:50:15.933+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:50:15.923+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:50:15.933+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:50:15.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.100 seconds
[2025-03-15T15:50:46.308+0000] {processor.py:157} INFO - Started process (PID=797) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:50:46.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:50:46.312+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:50:46.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:50:46.375+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:50:46.366+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:50:46.377+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:50:46.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.120 seconds
[2025-03-15T15:51:17.301+0000] {processor.py:157} INFO - Started process (PID=807) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:51:17.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:51:17.305+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:51:17.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:51:17.359+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:51:17.349+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:51:17.360+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:51:17.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.098 seconds
[2025-03-15T15:51:48.279+0000] {processor.py:157} INFO - Started process (PID=817) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:51:48.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:51:48.281+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:51:48.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:51:48.301+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:51:48.297+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:51:48.302+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:51:48.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T15:52:18.431+0000] {processor.py:157} INFO - Started process (PID=827) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:52:18.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:52:18.436+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:52:18.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:52:18.504+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:52:18.490+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:52:18.505+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:52:18.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.166 seconds
[2025-03-15T15:52:49.456+0000] {processor.py:157} INFO - Started process (PID=837) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:52:49.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:52:49.459+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:52:49.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:52:49.504+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:52:49.495+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:52:49.505+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:52:49.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.087 seconds
[2025-03-15T15:53:20.496+0000] {processor.py:157} INFO - Started process (PID=847) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:53:20.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:53:20.507+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:53:20.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:53:20.569+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:53:20.558+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:53:20.570+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:53:20.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.125 seconds
[2025-03-15T15:53:51.500+0000] {processor.py:157} INFO - Started process (PID=857) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:53:51.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:53:51.504+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:53:51.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:53:51.550+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:53:51.546+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:53:51.551+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:53:51.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.074 seconds
[2025-03-15T15:54:22.415+0000] {processor.py:157} INFO - Started process (PID=867) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:54:22.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:54:22.418+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:54:22.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:54:22.467+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:54:22.459+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:54:22.469+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:54:22.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.098 seconds
[2025-03-15T15:54:52.734+0000] {processor.py:157} INFO - Started process (PID=877) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:54:52.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:54:52.737+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:54:52.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:54:52.777+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:54:52.769+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:54:52.778+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:54:52.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.081 seconds
[2025-03-15T15:55:23.734+0000] {processor.py:157} INFO - Started process (PID=887) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:55:23.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:55:23.738+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:55:23.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:55:23.796+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:55:23.787+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:55:23.797+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:55:23.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.119 seconds
[2025-03-15T15:55:54.632+0000] {processor.py:157} INFO - Started process (PID=897) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:55:54.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:55:54.634+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:55:54.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:55:54.662+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:55:54.656+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:55:54.663+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:55:54.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.071 seconds
[2025-03-15T15:56:25.568+0000] {processor.py:157} INFO - Started process (PID=907) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:56:25.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:56:25.573+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:56:25.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:56:25.612+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:56:25.605+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:56:25.613+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:56:25.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.081 seconds
[2025-03-15T15:56:56.493+0000] {processor.py:157} INFO - Started process (PID=917) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:56:56.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:56:56.497+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:56:56.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:56:56.540+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:56:56.533+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:56:56.541+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:56:56.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.086 seconds
[2025-03-15T15:57:27.534+0000] {processor.py:157} INFO - Started process (PID=927) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:57:27.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:57:27.538+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:57:27.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:57:27.597+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:57:27.586+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:57:27.598+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:57:27.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.127 seconds
[2025-03-15T15:57:58.609+0000] {processor.py:157} INFO - Started process (PID=937) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:57:58.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:57:58.613+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:57:58.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:57:58.711+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:57:58.690+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:57:58.713+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:57:58.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.173 seconds
[2025-03-15T15:58:29.753+0000] {processor.py:157} INFO - Started process (PID=947) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:58:29.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:58:29.757+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:58:29.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:58:29.830+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:58:29.817+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:58:29.831+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:58:29.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.137 seconds
[2025-03-15T15:59:00.280+0000] {processor.py:157} INFO - Started process (PID=957) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:59:00.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:59:00.284+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:59:00.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:59:00.340+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:59:00.333+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:59:00.342+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:59:00.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.089 seconds
[2025-03-15T15:59:31.154+0000] {processor.py:157} INFO - Started process (PID=967) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T15:59:31.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T15:59:31.158+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:59:31.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T15:59:31.201+0000] {logging_mixin.py:151} INFO - [2025-03-15T15:59:31.193+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T15:59:31.202+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T15:59:31.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.082 seconds
[2025-03-15T16:00:02.060+0000] {processor.py:157} INFO - Started process (PID=977) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:00:02.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:00:02.063+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:00:02.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:00:02.103+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:00:02.097+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:00:02.105+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:00:02.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.072 seconds
[2025-03-15T16:00:33.011+0000] {processor.py:157} INFO - Started process (PID=987) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:00:33.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:00:33.017+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:00:33.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:00:33.062+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:00:33.055+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:00:33.063+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:00:33.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.090 seconds
[2025-03-15T16:01:03.981+0000] {processor.py:157} INFO - Started process (PID=997) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:01:03.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:01:03.983+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:01:03.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:01:04.022+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:01:04.012+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:01:04.023+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:01:04.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.073 seconds
[2025-03-15T16:01:34.900+0000] {processor.py:157} INFO - Started process (PID=1007) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:01:34.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:01:34.904+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:01:34.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:01:34.946+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:01:34.937+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:01:34.947+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:01:34.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.080 seconds
[2025-03-15T16:02:05.890+0000] {processor.py:157} INFO - Started process (PID=1017) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:02:05.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:02:05.894+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:02:05.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:02:05.947+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:02:05.936+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:02:05.949+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:02:05.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.094 seconds
[2025-03-15T16:02:36.891+0000] {processor.py:157} INFO - Started process (PID=1027) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:02:36.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:02:36.897+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:02:36.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:02:36.944+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:02:36.937+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:02:36.946+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:02:36.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.096 seconds
[2025-03-15T16:03:07.105+0000] {processor.py:157} INFO - Started process (PID=1037) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:03:07.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:03:07.108+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:03:07.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:03:07.145+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:03:07.137+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:03:07.146+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:03:07.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.071 seconds
[2025-03-15T16:03:38.074+0000] {processor.py:157} INFO - Started process (PID=1047) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:03:38.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:03:38.077+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:03:38.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:03:38.123+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:03:38.114+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:03:38.124+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:03:38.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.087 seconds
[2025-03-15T16:04:08.262+0000] {processor.py:157} INFO - Started process (PID=1057) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:04:08.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:04:08.265+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:04:08.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:04:08.314+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:04:08.307+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:04:08.316+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:04:08.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.093 seconds
[2025-03-15T16:04:39.339+0000] {processor.py:157} INFO - Started process (PID=1067) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:04:39.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:04:39.343+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:04:39.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:04:39.401+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:04:39.389+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:04:39.402+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:04:39.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.102 seconds
[2025-03-15T16:05:10.419+0000] {processor.py:157} INFO - Started process (PID=1077) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:05:10.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:05:10.428+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:05:10.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:05:10.470+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:05:10.461+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:05:10.471+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:05:10.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.089 seconds
[2025-03-15T16:05:41.481+0000] {processor.py:157} INFO - Started process (PID=1087) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:05:41.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:05:41.485+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:05:41.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:05:41.541+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:05:41.528+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:05:41.543+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:05:41.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.123 seconds
[2025-03-15T16:06:11.827+0000] {processor.py:157} INFO - Started process (PID=1097) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:06:11.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:06:11.833+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:06:11.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:06:11.899+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:06:11.890+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:06:11.901+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:06:11.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.119 seconds
[2025-03-15T16:06:42.123+0000] {processor.py:157} INFO - Started process (PID=1107) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:06:42.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:06:42.127+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:06:42.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:06:42.197+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:06:42.185+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:06:42.198+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:06:42.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.128 seconds
[2025-03-15T16:07:12.637+0000] {processor.py:157} INFO - Started process (PID=1117) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:07:12.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:07:12.639+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:07:12.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:07:12.678+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:07:12.670+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:07:12.679+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:07:12.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.072 seconds
[2025-03-15T16:07:43.525+0000] {processor.py:157} INFO - Started process (PID=1127) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:07:43.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:07:43.528+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:07:43.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:07:43.551+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:07:43.548+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:07:43.552+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:07:43.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.052 seconds
[2025-03-15T16:08:13.677+0000] {processor.py:157} INFO - Started process (PID=1137) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:08:13.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:08:13.681+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:08:13.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:08:13.741+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:08:13.733+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:08:13.742+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:08:13.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.133 seconds
[2025-03-15T16:08:43.865+0000] {processor.py:157} INFO - Started process (PID=1147) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:08:43.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:08:43.867+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:08:43.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:08:43.887+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:08:43.882+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:08:43.887+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:08:43.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T16:09:14.799+0000] {processor.py:157} INFO - Started process (PID=1157) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:09:14.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:09:14.802+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:09:14.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:09:14.821+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:09:14.817+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:09:14.821+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:09:14.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T16:09:45.685+0000] {processor.py:157} INFO - Started process (PID=1167) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:09:45.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:09:45.687+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:09:45.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:09:45.708+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:09:45.705+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:09:45.709+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:09:45.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T16:10:16.485+0000] {processor.py:157} INFO - Started process (PID=1177) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:10:16.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:10:16.488+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:10:16.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:10:16.510+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:10:16.505+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:10:16.511+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:10:16.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T16:10:47.503+0000] {processor.py:157} INFO - Started process (PID=1187) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:10:47.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:10:47.519+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:10:47.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:10:47.621+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:10:47.606+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:10:47.623+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:10:47.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.265 seconds
[2025-03-15T16:11:18.550+0000] {processor.py:157} INFO - Started process (PID=1197) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:11:18.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:11:18.568+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:11:18.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:11:18.662+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:11:18.649+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:11:18.664+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:11:18.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.267 seconds
[2025-03-15T16:11:48.929+0000] {processor.py:157} INFO - Started process (PID=1207) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:11:48.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:11:48.943+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:11:48.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:11:48.998+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:11:48.984+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:11:48.999+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:11:49.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.181 seconds
[2025-03-15T16:12:19.864+0000] {processor.py:157} INFO - Started process (PID=1217) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:12:19.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:12:19.869+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:12:19.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:12:19.949+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:12:19.941+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:12:19.951+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:12:20.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.154 seconds
[2025-03-15T16:12:50.258+0000] {processor.py:157} INFO - Started process (PID=1227) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:12:50.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:12:50.262+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:12:50.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:12:50.312+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:12:50.304+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:12:50.313+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:12:50.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.115 seconds
[2025-03-15T16:13:21.177+0000] {processor.py:157} INFO - Started process (PID=1237) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:13:21.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:13:21.181+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:13:21.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:13:21.224+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:13:21.214+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:13:21.225+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:13:21.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.092 seconds
[2025-03-15T16:13:52.044+0000] {processor.py:157} INFO - Started process (PID=1247) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:13:52.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:13:52.046+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:13:52.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:13:52.077+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:13:52.072+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:13:52.077+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:13:52.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T16:14:22.977+0000] {processor.py:157} INFO - Started process (PID=1257) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:14:22.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:14:22.980+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:14:22.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:14:23.006+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:14:23.002+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:14:23.006+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:14:23.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.054 seconds
[2025-03-15T16:14:53.884+0000] {processor.py:157} INFO - Started process (PID=1267) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:14:53.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:14:53.889+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:14:53.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:14:53.923+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:14:53.916+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:14:53.924+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:14:53.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.078 seconds
[2025-03-15T16:15:24.685+0000] {processor.py:157} INFO - Started process (PID=1277) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:15:24.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:15:24.689+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:15:24.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:15:24.739+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:15:24.730+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:15:24.740+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:15:24.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.100 seconds
[2025-03-15T16:15:54.997+0000] {processor.py:157} INFO - Started process (PID=1287) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:15:54.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:15:54.999+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:15:54.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:15:55.032+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:15:55.025+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:15:55.033+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:15:55.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.062 seconds
[2025-03-15T16:16:25.814+0000] {processor.py:157} INFO - Started process (PID=1297) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:16:25.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:16:25.819+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:16:25.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:16:25.861+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:16:25.852+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:16:25.862+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:16:25.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.088 seconds
[2025-03-15T16:16:56.701+0000] {processor.py:157} INFO - Started process (PID=1307) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:16:56.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:16:56.712+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:16:56.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:16:56.816+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:16:56.793+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:16:56.818+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:16:56.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.205 seconds
[2025-03-15T16:17:27.487+0000] {processor.py:157} INFO - Started process (PID=1317) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:17:27.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:17:27.490+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:17:27.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:17:27.509+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:17:27.506+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:17:27.510+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:17:27.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T16:17:58.375+0000] {processor.py:157} INFO - Started process (PID=1327) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:17:58.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:17:58.378+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:17:58.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:17:58.404+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:17:58.400+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:17:58.405+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:17:58.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.054 seconds
[2025-03-15T16:18:29.303+0000] {processor.py:157} INFO - Started process (PID=1337) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:18:29.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:18:29.306+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:18:29.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:18:29.348+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:18:29.338+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:18:29.349+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:18:29.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.101 seconds
[2025-03-15T16:19:00.149+0000] {processor.py:157} INFO - Started process (PID=1347) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:19:00.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:19:00.151+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:19:00.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:19:00.176+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:19:00.171+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:19:00.177+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:19:00.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.057 seconds
[2025-03-15T16:19:31.088+0000] {processor.py:157} INFO - Started process (PID=1357) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:19:31.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:19:31.092+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:19:31.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:19:31.121+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:19:31.116+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:19:31.130+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:19:31.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.075 seconds
[2025-03-15T16:20:01.286+0000] {processor.py:157} INFO - Started process (PID=1367) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:20:01.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:20:01.289+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:20:01.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:20:01.314+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:20:01.309+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:20:01.315+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:20:01.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.060 seconds
[2025-03-15T16:20:32.164+0000] {processor.py:157} INFO - Started process (PID=1377) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:20:32.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:20:32.167+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:20:32.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:20:32.193+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:20:32.188+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:20:32.195+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:20:32.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.070 seconds
[2025-03-15T16:21:03.089+0000] {processor.py:157} INFO - Started process (PID=1387) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:21:03.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:21:03.092+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:21:03.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:21:03.131+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:21:03.125+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:21:03.132+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:21:03.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.079 seconds
[2025-03-15T16:21:33.888+0000] {processor.py:157} INFO - Started process (PID=1397) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:21:33.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:21:33.891+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:21:33.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:21:33.928+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:21:33.920+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:21:33.929+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:21:33.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.080 seconds
[2025-03-15T16:22:04.748+0000] {processor.py:157} INFO - Started process (PID=1407) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:22:04.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:22:04.751+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:22:04.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:22:04.795+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:22:04.786+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:22:04.796+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:22:04.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.085 seconds
[2025-03-15T16:22:35.706+0000] {processor.py:157} INFO - Started process (PID=1417) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:22:35.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:22:35.713+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:22:35.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:22:35.788+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:22:35.771+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:22:35.791+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:22:35.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.165 seconds
[2025-03-15T16:23:06.692+0000] {processor.py:157} INFO - Started process (PID=1427) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:23:06.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:23:06.695+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:23:06.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:23:06.719+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:23:06.715+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:23:06.719+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:23:06.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.052 seconds
[2025-03-15T16:23:37.541+0000] {processor.py:157} INFO - Started process (PID=1437) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:23:37.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:23:37.545+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:23:37.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:23:37.588+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:23:37.578+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:23:37.589+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:23:37.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.081 seconds
[2025-03-15T16:24:07.659+0000] {processor.py:157} INFO - Started process (PID=1447) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:24:07.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:24:07.661+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:24:07.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:24:07.680+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:24:07.677+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:24:07.680+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:24:07.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.046 seconds
[2025-03-15T16:24:38.535+0000] {processor.py:157} INFO - Started process (PID=1457) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:24:38.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:24:38.537+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:24:38.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:24:38.556+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:24:38.553+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:24:38.556+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:24:38.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.044 seconds
[2025-03-15T16:25:09.469+0000] {processor.py:157} INFO - Started process (PID=1467) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:25:09.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:25:09.473+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:25:09.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:25:09.503+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:25:09.499+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:25:09.504+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:25:09.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.060 seconds
[2025-03-15T16:25:40.279+0000] {processor.py:157} INFO - Started process (PID=1477) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:25:40.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:25:40.283+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:25:40.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:25:40.312+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:25:40.305+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:25:40.313+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:25:40.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T16:26:11.203+0000] {processor.py:157} INFO - Started process (PID=1487) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:26:11.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:26:11.205+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:26:11.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:26:11.234+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:26:11.228+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:26:11.235+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:26:11.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.063 seconds
[2025-03-15T16:26:42.097+0000] {processor.py:157} INFO - Started process (PID=1497) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:26:42.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:26:42.099+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:26:42.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:26:42.119+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:26:42.115+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:26:42.119+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:26:42.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T16:27:12.994+0000] {processor.py:157} INFO - Started process (PID=1507) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:27:12.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:27:12.996+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:27:12.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:27:13.014+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:27:13.011+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:27:13.015+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:27:13.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T16:27:43.856+0000] {processor.py:157} INFO - Started process (PID=1517) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:27:43.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:27:43.858+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:27:43.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:27:43.880+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:27:43.877+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:27:43.881+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:27:43.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T16:28:14.149+0000] {processor.py:157} INFO - Started process (PID=1527) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:28:14.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:28:14.151+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:28:14.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:28:14.194+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:28:14.185+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:28:14.195+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:28:14.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.072 seconds
[2025-03-15T16:28:45.053+0000] {processor.py:157} INFO - Started process (PID=1537) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:28:45.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:28:45.056+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:28:45.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:28:45.082+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:28:45.077+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:28:45.082+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:28:45.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.059 seconds
[2025-03-15T16:29:15.961+0000] {processor.py:157} INFO - Started process (PID=1547) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:29:15.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:29:15.964+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:29:15.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:29:15.988+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:29:15.983+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:29:15.989+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:29:16.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T16:29:46.902+0000] {processor.py:157} INFO - Started process (PID=1557) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:29:46.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:29:46.904+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:29:46.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:29:46.931+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:29:46.925+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:29:46.932+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:29:46.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.056 seconds
[2025-03-15T16:30:17.806+0000] {processor.py:157} INFO - Started process (PID=1567) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:30:17.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:30:17.810+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:30:17.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:30:17.841+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:30:17.835+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:30:17.842+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:30:17.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.067 seconds
[2025-03-15T16:30:48.624+0000] {processor.py:157} INFO - Started process (PID=1577) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:30:48.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:30:48.626+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:30:48.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:30:48.644+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:30:48.641+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:30:48.645+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:30:48.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.046 seconds
[2025-03-15T16:31:19.584+0000] {processor.py:157} INFO - Started process (PID=1587) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:31:19.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:31:19.586+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:31:19.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:31:19.606+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:31:19.603+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:31:19.607+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:31:19.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.053 seconds
[2025-03-15T16:31:50.423+0000] {processor.py:157} INFO - Started process (PID=1597) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:31:50.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:31:50.425+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:31:50.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:31:50.443+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:31:50.439+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:31:50.443+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:31:50.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.044 seconds
[2025-03-15T16:32:20.736+0000] {processor.py:157} INFO - Started process (PID=1607) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:32:20.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:32:20.738+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:32:20.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:32:20.758+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:32:20.755+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:32:20.759+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:32:20.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T16:32:51.679+0000] {processor.py:157} INFO - Started process (PID=1617) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:32:51.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:32:51.681+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:32:51.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:32:51.699+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:32:51.696+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:32:51.699+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:32:51.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.056 seconds
[2025-03-15T16:33:22.609+0000] {processor.py:157} INFO - Started process (PID=1627) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:33:22.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:33:22.612+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:33:22.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:33:22.649+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:33:22.643+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:33:22.650+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:33:22.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.081 seconds
[2025-03-15T16:33:53.496+0000] {processor.py:157} INFO - Started process (PID=1637) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:33:53.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:33:53.500+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:33:53.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:33:53.551+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:33:53.537+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:33:53.553+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:33:53.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.093 seconds
[2025-03-15T16:34:24.391+0000] {processor.py:157} INFO - Started process (PID=1647) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:34:24.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:34:24.393+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:34:24.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:34:24.416+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:34:24.412+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:34:24.417+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:34:24.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T16:34:55.198+0000] {processor.py:157} INFO - Started process (PID=1657) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:34:55.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:34:55.200+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:34:55.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:34:55.220+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:34:55.217+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:34:55.221+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:34:55.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.048 seconds
[2025-03-15T16:35:26.108+0000] {processor.py:157} INFO - Started process (PID=1667) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:35:26.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:35:26.114+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:35:26.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:35:26.145+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:35:26.137+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:35:26.146+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:35:26.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.091 seconds
[2025-03-15T16:35:57.094+0000] {processor.py:157} INFO - Started process (PID=1677) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:35:57.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:35:57.098+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:35:57.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:35:57.135+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:35:57.128+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:35:57.136+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:35:57.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.099 seconds
[2025-03-15T16:36:27.362+0000] {processor.py:157} INFO - Started process (PID=1687) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:36:27.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:36:27.366+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:36:27.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:36:27.408+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:36:27.402+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:36:27.409+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:36:27.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.093 seconds
[2025-03-15T16:36:58.207+0000] {processor.py:157} INFO - Started process (PID=1697) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:36:58.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:36:58.213+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:36:58.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:36:58.249+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:36:58.242+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:36:58.249+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:36:58.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.084 seconds
[2025-03-15T16:37:29.021+0000] {processor.py:157} INFO - Started process (PID=1707) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:37:29.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:37:29.023+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:37:29.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:37:29.044+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:37:29.041+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:37:29.045+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:37:29.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T16:37:59.906+0000] {processor.py:157} INFO - Started process (PID=1717) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:37:59.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:37:59.908+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:37:59.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:37:59.928+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:37:59.925+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:37:59.929+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:37:59.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.048 seconds
[2025-03-15T16:38:30.803+0000] {processor.py:157} INFO - Started process (PID=1727) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:38:30.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:38:30.806+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:38:30.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:38:30.831+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:38:30.826+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:38:30.832+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:38:30.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T16:39:01.759+0000] {processor.py:157} INFO - Started process (PID=1737) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:39:01.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:39:01.762+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:39:01.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:39:01.780+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:39:01.777+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:39:01.780+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:39:01.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.046 seconds
[2025-03-15T16:39:32.717+0000] {processor.py:157} INFO - Started process (PID=1747) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:39:32.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:39:32.721+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:39:32.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:39:32.749+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:39:32.745+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:39:32.750+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:39:32.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.061 seconds
[2025-03-15T16:40:03.504+0000] {processor.py:157} INFO - Started process (PID=1757) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:40:03.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:40:03.506+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:40:03.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:40:03.525+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:40:03.522+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:40:03.526+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:40:03.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T16:40:33.834+0000] {processor.py:157} INFO - Started process (PID=1767) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:40:33.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:40:33.837+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:40:33.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:40:33.866+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:40:33.860+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:40:33.867+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:40:33.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.066 seconds
[2025-03-15T16:41:04.077+0000] {processor.py:157} INFO - Started process (PID=1777) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:41:04.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:41:04.080+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:41:04.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:41:04.099+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:41:04.095+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:41:04.099+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:41:04.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.048 seconds
[2025-03-15T16:41:34.983+0000] {processor.py:157} INFO - Started process (PID=1787) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:41:34.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:41:34.986+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:41:34.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:41:35.015+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:41:35.009+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:41:35.016+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:41:35.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.060 seconds
[2025-03-15T16:42:05.917+0000] {processor.py:157} INFO - Started process (PID=1797) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:42:05.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:42:05.919+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:42:05.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:42:05.938+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:42:05.934+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:42:05.938+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:42:05.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.046 seconds
[2025-03-15T16:42:36.895+0000] {processor.py:157} INFO - Started process (PID=1807) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:42:36.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:42:36.897+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:42:36.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:42:36.923+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:42:36.917+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:42:36.924+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:42:36.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T16:43:07.824+0000] {processor.py:157} INFO - Started process (PID=1817) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:43:07.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:43:07.826+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:43:07.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:43:07.862+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:43:07.856+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:43:07.863+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:43:07.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.067 seconds
[2025-03-15T16:43:38.696+0000] {processor.py:157} INFO - Started process (PID=1827) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:43:38.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:43:38.699+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:43:38.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:43:38.721+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:43:38.718+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:43:38.722+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:43:38.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.055 seconds
[2025-03-15T16:44:09.643+0000] {processor.py:157} INFO - Started process (PID=1837) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:44:09.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:44:09.645+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:44:09.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:44:09.666+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:44:09.663+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:44:09.667+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:44:09.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T16:44:39.875+0000] {processor.py:157} INFO - Started process (PID=1847) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:44:39.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:44:39.877+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:44:39.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:44:39.896+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:44:39.892+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:44:39.896+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:44:39.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T16:45:10.764+0000] {processor.py:157} INFO - Started process (PID=1857) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:45:10.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:45:10.766+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:45:10.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:45:10.784+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:45:10.780+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:45:10.785+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:45:10.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.045 seconds
[2025-03-15T16:45:41.636+0000] {processor.py:157} INFO - Started process (PID=1867) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:45:41.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:45:41.640+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:45:41.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:45:41.682+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:45:41.677+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:45:41.683+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:45:41.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.079 seconds
[2025-03-15T16:46:12.522+0000] {processor.py:157} INFO - Started process (PID=1877) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:46:12.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:46:12.525+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:46:12.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:46:12.547+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:46:12.543+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:46:12.548+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:46:12.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.053 seconds
[2025-03-15T16:46:43.333+0000] {processor.py:157} INFO - Started process (PID=1887) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:46:43.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:46:43.335+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:46:43.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:46:43.353+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:46:43.350+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:46:43.354+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:46:43.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T16:47:14.215+0000] {processor.py:157} INFO - Started process (PID=1897) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:47:14.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:47:14.218+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:47:14.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:47:14.253+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:47:14.247+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:47:14.254+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:47:14.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.069 seconds
[2025-03-15T16:47:45.040+0000] {processor.py:157} INFO - Started process (PID=1907) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:47:45.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:47:45.042+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:47:45.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:47:45.062+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:47:45.057+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:47:45.063+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:47:45.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T16:48:15.867+0000] {processor.py:157} INFO - Started process (PID=1917) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:48:15.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:48:15.869+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:48:15.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:48:15.894+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:48:15.889+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:48:15.895+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:48:15.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.055 seconds
[2025-03-15T16:48:46.177+0000] {processor.py:157} INFO - Started process (PID=1927) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:48:46.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:48:46.179+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:48:46.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:48:46.211+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:48:46.205+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:48:46.212+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:48:46.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T16:49:16.295+0000] {processor.py:157} INFO - Started process (PID=1937) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:49:16.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:49:16.297+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:49:16.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:49:16.345+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:49:16.331+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:49:16.346+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:49:16.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.094 seconds
[2025-03-15T16:49:47.146+0000] {processor.py:157} INFO - Started process (PID=1947) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:49:47.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:49:47.149+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:49:47.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:49:47.179+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:49:47.175+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:49:47.180+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:49:47.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.068 seconds
[2025-03-15T16:50:17.968+0000] {processor.py:157} INFO - Started process (PID=1957) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:50:17.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:50:17.970+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:50:17.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:50:17.991+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:50:17.988+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:50:17.992+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:50:18.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.051 seconds
[2025-03-15T16:50:48.997+0000] {processor.py:157} INFO - Started process (PID=1967) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:50:48.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:50:48.999+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:50:48.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:50:49.018+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:50:49.015+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:50:49.019+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:50:49.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.051 seconds
[2025-03-15T16:51:19.840+0000] {processor.py:157} INFO - Started process (PID=1977) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:51:19.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:51:19.843+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:51:19.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:51:19.865+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:51:19.860+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:51:19.866+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:51:19.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.060 seconds
[2025-03-15T16:51:50.674+0000] {processor.py:157} INFO - Started process (PID=1987) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:51:50.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:51:50.676+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:51:50.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:51:50.694+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:51:50.691+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:51:50.695+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:51:50.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.046 seconds
[2025-03-15T16:52:21.571+0000] {processor.py:157} INFO - Started process (PID=1997) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:52:21.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:52:21.575+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:52:21.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:52:21.606+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:52:21.601+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:52:21.607+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:52:21.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.071 seconds
[2025-03-15T16:52:51.790+0000] {processor.py:157} INFO - Started process (PID=2007) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:52:51.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:52:51.793+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:52:51.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:52:51.831+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:52:51.823+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:52:51.832+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:52:51.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.082 seconds
[2025-03-15T16:53:22.587+0000] {processor.py:157} INFO - Started process (PID=2017) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:53:22.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:53:22.590+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:53:22.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:53:22.629+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:53:22.624+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:53:22.630+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:53:22.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.070 seconds
[2025-03-15T16:53:53.459+0000] {processor.py:157} INFO - Started process (PID=2027) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:53:53.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:53:53.463+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:53:53.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:53:53.505+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:53:53.497+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:53:53.507+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:53:53.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.084 seconds
[2025-03-15T16:54:24.468+0000] {processor.py:157} INFO - Started process (PID=2037) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:54:24.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:54:24.470+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:54:24.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:54:24.491+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:54:24.488+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:54:24.492+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:54:24.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T16:54:55.367+0000] {processor.py:157} INFO - Started process (PID=2047) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:54:55.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:54:55.369+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:54:55.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:54:55.392+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:54:55.387+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:54:55.393+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:54:55.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.056 seconds
[2025-03-15T16:55:26.421+0000] {processor.py:157} INFO - Started process (PID=2057) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:55:26.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:55:26.422+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:55:26.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:55:26.449+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:55:26.445+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:55:26.449+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:55:26.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.052 seconds
[2025-03-15T16:55:57.287+0000] {processor.py:157} INFO - Started process (PID=2067) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:55:57.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:55:57.289+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:55:57.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:55:57.307+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:55:57.304+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:55:57.308+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:55:57.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.046 seconds
[2025-03-15T16:56:28.071+0000] {processor.py:157} INFO - Started process (PID=2077) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:56:28.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:56:28.074+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:56:28.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:56:28.101+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:56:28.097+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:56:28.102+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:56:28.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.067 seconds
[2025-03-15T16:56:58.250+0000] {processor.py:157} INFO - Started process (PID=2087) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:56:58.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:56:58.252+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:56:58.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:56:58.278+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:56:58.273+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:56:58.279+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:56:58.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.057 seconds
[2025-03-15T16:57:29.134+0000] {processor.py:157} INFO - Started process (PID=2097) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:57:29.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:57:29.137+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:57:29.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:57:29.173+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:57:29.166+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:57:29.175+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:57:29.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.074 seconds
[2025-03-15T16:58:00.068+0000] {processor.py:157} INFO - Started process (PID=2107) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:58:00.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:58:00.073+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:58:00.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:58:00.106+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:58:00.101+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:58:00.107+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:58:00.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.080 seconds
[2025-03-15T16:58:30.943+0000] {processor.py:157} INFO - Started process (PID=2117) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:58:30.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:58:30.945+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:58:30.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:58:30.969+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:58:30.964+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:58:30.970+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:58:30.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.056 seconds
[2025-03-15T16:59:01.916+0000] {processor.py:157} INFO - Started process (PID=2127) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:59:01.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:59:01.919+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:59:01.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:59:01.948+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:59:01.940+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:59:01.949+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:59:01.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T16:59:32.726+0000] {processor.py:157} INFO - Started process (PID=2137) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T16:59:32.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T16:59:32.728+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:59:32.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T16:59:32.753+0000] {logging_mixin.py:151} INFO - [2025-03-15T16:59:32.749+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T16:59:32.754+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T16:59:32.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.055 seconds
[2025-03-15T17:00:03.485+0000] {processor.py:157} INFO - Started process (PID=2147) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:00:03.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:00:03.488+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:00:03.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:00:03.514+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:00:03.510+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:00:03.515+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:00:03.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T17:00:34.432+0000] {processor.py:157} INFO - Started process (PID=2157) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:00:34.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:00:34.434+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:00:34.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:00:34.452+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:00:34.449+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:00:34.453+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:00:34.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.048 seconds
[2025-03-15T17:01:04.803+0000] {processor.py:157} INFO - Started process (PID=2167) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:01:04.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:01:04.805+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:01:04.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:01:04.846+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:01:04.838+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:01:04.848+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:01:04.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.092 seconds
[2025-03-15T17:01:35.768+0000] {processor.py:157} INFO - Started process (PID=2177) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:01:35.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:01:35.770+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:01:35.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:01:35.792+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:01:35.786+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:01:35.792+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:01:35.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T17:02:06.737+0000] {processor.py:157} INFO - Started process (PID=2187) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:02:06.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:02:06.740+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:02:06.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:02:06.759+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:02:06.755+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:02:06.760+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:02:06.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T17:02:37.691+0000] {processor.py:157} INFO - Started process (PID=2197) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:02:37.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:02:37.693+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:02:37.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:02:37.722+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:02:37.717+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:02:37.723+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:02:37.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.065 seconds
[2025-03-15T17:03:08.733+0000] {processor.py:157} INFO - Started process (PID=2207) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:03:08.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:03:08.735+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:03:08.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:03:08.755+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:03:08.752+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:03:08.756+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:03:08.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T17:03:39.775+0000] {processor.py:157} INFO - Started process (PID=2217) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:03:39.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:03:39.778+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:03:39.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:03:39.809+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:03:39.804+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:03:39.810+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:03:39.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.078 seconds
[2025-03-15T17:04:09.932+0000] {processor.py:157} INFO - Started process (PID=2227) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:04:09.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:04:09.934+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:04:09.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:04:09.956+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:04:09.952+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:04:09.956+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:04:09.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.052 seconds
[2025-03-15T17:04:40.764+0000] {processor.py:157} INFO - Started process (PID=2237) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:04:40.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:04:40.766+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:04:40.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:04:40.787+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:04:40.783+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:04:40.788+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:04:40.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T17:05:11.166+0000] {processor.py:157} INFO - Started process (PID=2247) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:05:11.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:05:11.169+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:05:11.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:05:11.188+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:05:11.185+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:05:11.189+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:05:11.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T17:05:41.282+0000] {processor.py:157} INFO - Started process (PID=2257) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:05:41.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:05:41.285+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:05:41.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:05:41.311+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:05:41.306+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:05:41.312+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:05:41.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.060 seconds
[2025-03-15T17:06:12.202+0000] {processor.py:157} INFO - Started process (PID=2267) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:06:12.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:06:12.204+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:06:12.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:06:12.235+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:06:12.226+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:06:12.236+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:06:12.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.070 seconds
[2025-03-15T17:06:43.200+0000] {processor.py:157} INFO - Started process (PID=2277) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:06:43.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:06:43.203+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:06:43.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:06:43.231+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:06:43.225+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:06:43.231+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:06:43.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.062 seconds
[2025-03-15T17:07:14.059+0000] {processor.py:157} INFO - Started process (PID=2287) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:07:14.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:07:14.062+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:07:14.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:07:14.087+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:07:14.082+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:07:14.088+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:07:14.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.067 seconds
[2025-03-15T17:07:45.102+0000] {processor.py:157} INFO - Started process (PID=2297) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:07:45.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:07:45.105+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:07:45.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:07:45.138+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:07:45.131+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:07:45.139+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:07:45.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.066 seconds
[2025-03-15T17:08:15.895+0000] {processor.py:157} INFO - Started process (PID=2307) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:08:15.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:08:15.902+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:08:15.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:08:15.947+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:08:15.939+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:08:15.948+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:08:15.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.094 seconds
[2025-03-15T17:08:46.695+0000] {processor.py:157} INFO - Started process (PID=2317) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:08:46.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:08:46.698+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:08:46.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:08:46.735+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:08:46.728+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:08:46.736+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:08:46.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.085 seconds
[2025-03-15T17:09:17.067+0000] {processor.py:157} INFO - Started process (PID=2327) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:09:17.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:09:17.070+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:09:17.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:09:17.094+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:09:17.090+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:09:17.095+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:09:17.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.070 seconds
[2025-03-15T17:09:47.958+0000] {processor.py:157} INFO - Started process (PID=2337) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:09:47.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:09:47.960+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:09:47.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:09:47.986+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:09:47.981+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:09:47.987+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:09:48.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T17:10:18.839+0000] {processor.py:157} INFO - Started process (PID=2347) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:10:18.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:10:18.841+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:10:18.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:10:18.864+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:10:18.859+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:10:18.865+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:10:18.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.051 seconds
[2025-03-15T17:10:49.745+0000] {processor.py:157} INFO - Started process (PID=2357) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:10:49.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:10:49.748+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:10:49.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:10:49.767+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:10:49.764+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:10:49.768+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:10:49.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T17:11:20.694+0000] {processor.py:157} INFO - Started process (PID=2367) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:11:20.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:11:20.696+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:11:20.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:11:20.722+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:11:20.717+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:11:20.723+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:11:20.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.082 seconds
[2025-03-15T17:11:51.647+0000] {processor.py:157} INFO - Started process (PID=2377) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:11:51.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:11:51.650+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:11:51.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:11:51.708+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:11:51.697+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:11:51.709+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:11:51.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.104 seconds
[2025-03-15T17:12:22.577+0000] {processor.py:157} INFO - Started process (PID=2387) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:12:22.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:12:22.582+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:12:22.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:12:22.627+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:12:22.619+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:12:22.629+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:12:22.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.139 seconds
[2025-03-15T17:12:53.340+0000] {processor.py:157} INFO - Started process (PID=2397) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:12:53.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:12:53.344+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:12:53.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:12:53.390+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:12:53.381+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:12:53.391+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:12:53.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.082 seconds
[2025-03-15T17:13:24.091+0000] {processor.py:157} INFO - Started process (PID=2407) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:13:24.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:13:24.093+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:13:24.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:13:24.112+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:13:24.109+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:13:24.112+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:13:24.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.043 seconds
[2025-03-15T17:13:55.062+0000] {processor.py:157} INFO - Started process (PID=2417) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:13:55.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:13:55.064+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:13:55.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:13:55.081+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:13:55.078+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:13:55.082+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:13:55.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.045 seconds
[2025-03-15T17:14:25.260+0000] {processor.py:157} INFO - Started process (PID=2427) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:14:25.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:14:25.262+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:14:25.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:14:25.281+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:14:25.278+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:14:25.281+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:14:25.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.043 seconds
[2025-03-15T17:14:56.150+0000] {processor.py:157} INFO - Started process (PID=2437) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:14:56.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:14:56.152+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:14:56.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:14:56.173+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:14:56.169+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:14:56.173+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:14:56.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T17:15:27.035+0000] {processor.py:157} INFO - Started process (PID=2447) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:15:27.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:15:27.037+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:15:27.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:15:27.067+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:15:27.061+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:15:27.067+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:15:27.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.055 seconds
[2025-03-15T17:15:57.885+0000] {processor.py:157} INFO - Started process (PID=2457) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:15:57.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:15:57.888+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:15:57.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:15:57.919+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:15:57.913+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:15:57.920+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:15:57.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.068 seconds
[2025-03-15T17:16:28.698+0000] {processor.py:157} INFO - Started process (PID=2467) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:16:28.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:16:28.700+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:16:28.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:16:28.724+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:16:28.720+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:16:28.725+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:16:28.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.053 seconds
[2025-03-15T17:16:59.527+0000] {processor.py:157} INFO - Started process (PID=2477) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:16:59.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:16:59.530+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:16:59.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:16:59.547+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:16:59.544+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:16:59.547+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:16:59.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.044 seconds
[2025-03-15T17:17:29.776+0000] {processor.py:157} INFO - Started process (PID=2487) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:17:29.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:17:29.782+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:17:29.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:17:29.855+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:17:29.846+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:17:29.857+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:17:29.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.171 seconds
[2025-03-15T17:18:00.660+0000] {processor.py:157} INFO - Started process (PID=2497) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:18:00.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:18:00.663+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:18:00.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:18:00.689+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:18:00.685+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:18:00.690+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:18:00.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.060 seconds
[2025-03-15T17:18:31.537+0000] {processor.py:157} INFO - Started process (PID=2507) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:18:31.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:18:31.539+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:18:31.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:18:31.557+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:18:31.554+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:18:31.557+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:18:31.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.046 seconds
[2025-03-15T17:19:02.412+0000] {processor.py:157} INFO - Started process (PID=2517) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:19:02.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:19:02.415+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:19:02.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:19:02.454+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:19:02.448+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:19:02.455+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:19:02.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.074 seconds
[2025-03-15T17:19:33.405+0000] {processor.py:157} INFO - Started process (PID=2527) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:19:33.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:19:33.407+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:19:33.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:19:33.433+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:19:33.428+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:19:33.434+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:19:33.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.055 seconds
[2025-03-15T17:20:04.281+0000] {processor.py:157} INFO - Started process (PID=2537) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:20:04.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:20:04.283+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:20:04.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:20:04.302+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:20:04.298+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:20:04.302+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:20:04.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T17:20:35.095+0000] {processor.py:157} INFO - Started process (PID=2547) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:20:35.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:20:35.097+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:20:35.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:20:35.125+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:20:35.119+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:20:35.126+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:20:35.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.061 seconds
[2025-03-15T17:21:05.880+0000] {processor.py:157} INFO - Started process (PID=2557) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:21:05.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:21:05.882+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:21:05.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:21:05.914+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:21:05.908+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:21:05.914+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:21:05.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.062 seconds
[2025-03-15T17:21:36.147+0000] {processor.py:157} INFO - Started process (PID=2567) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:21:36.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:21:36.149+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:21:36.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:21:36.167+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:21:36.164+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:21:36.168+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:21:36.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.046 seconds
[2025-03-15T17:22:07.027+0000] {processor.py:157} INFO - Started process (PID=2577) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:22:07.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:22:07.031+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:22:07.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:22:07.060+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:22:07.054+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:22:07.061+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:22:07.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.062 seconds
[2025-03-15T17:22:37.889+0000] {processor.py:157} INFO - Started process (PID=2587) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:22:37.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:22:37.892+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:22:37.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:22:37.917+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:22:37.913+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:22:37.918+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:22:37.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T17:23:08.822+0000] {processor.py:157} INFO - Started process (PID=2597) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:23:08.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:23:08.824+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:23:08.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:23:08.842+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:23:08.839+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:23:08.843+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:23:08.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T17:23:39.686+0000] {processor.py:157} INFO - Started process (PID=2607) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:23:39.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:23:39.690+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:23:39.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:23:39.735+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:23:39.726+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:23:39.736+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:23:39.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.085 seconds
[2025-03-15T17:24:10.647+0000] {processor.py:157} INFO - Started process (PID=2617) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:24:10.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:24:10.650+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:24:10.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:24:10.697+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:24:10.690+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:24:10.698+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:24:10.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.095 seconds
[2025-03-15T17:24:41.410+0000] {processor.py:157} INFO - Started process (PID=2627) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:24:41.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:24:41.412+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:24:41.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:24:41.435+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:24:41.432+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:24:41.436+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:24:41.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T17:25:12.326+0000] {processor.py:157} INFO - Started process (PID=2637) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:25:12.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:25:12.328+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:25:12.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:25:12.351+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:25:12.347+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:25:12.351+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:25:12.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T17:25:42.501+0000] {processor.py:157} INFO - Started process (PID=2647) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:25:42.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:25:42.505+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:25:42.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:25:42.543+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:25:42.537+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:25:42.544+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:25:42.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.070 seconds
[2025-03-15T17:26:13.451+0000] {processor.py:157} INFO - Started process (PID=2657) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:26:13.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:26:13.453+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:26:13.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:26:13.476+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:26:13.472+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:26:13.476+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:26:13.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T17:26:44.308+0000] {processor.py:157} INFO - Started process (PID=2667) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:26:44.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:26:44.310+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:26:44.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:26:44.334+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:26:44.331+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:26:44.335+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:26:44.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T17:27:15.061+0000] {processor.py:157} INFO - Started process (PID=2677) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:27:15.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:27:15.064+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:27:15.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:27:15.091+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:27:15.087+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:27:15.092+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:27:15.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.066 seconds
[2025-03-15T17:27:45.861+0000] {processor.py:157} INFO - Started process (PID=2687) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:27:45.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:27:45.863+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:27:45.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:27:45.883+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:27:45.879+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:27:45.884+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:27:45.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T17:28:16.708+0000] {processor.py:157} INFO - Started process (PID=2697) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:28:16.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:28:16.710+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:28:16.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:28:16.731+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:28:16.727+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:28:16.732+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:28:16.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.048 seconds
[2025-03-15T17:28:47.601+0000] {processor.py:157} INFO - Started process (PID=2707) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:28:47.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:28:47.603+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:28:47.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:28:47.624+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:28:47.621+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:28:47.625+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:28:47.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T17:29:18.489+0000] {processor.py:157} INFO - Started process (PID=2717) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:29:18.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:29:18.493+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:29:18.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:29:18.514+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:29:18.510+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:29:18.515+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:29:18.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T17:29:48.806+0000] {processor.py:157} INFO - Started process (PID=2727) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:29:48.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:29:48.808+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:29:48.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:29:48.824+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:29:48.821+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:29:48.825+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:29:48.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.043 seconds
[2025-03-15T17:30:19.705+0000] {processor.py:157} INFO - Started process (PID=2737) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:30:19.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:30:19.707+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:30:19.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:30:19.725+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:30:19.722+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:30:19.725+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:30:19.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.047 seconds
[2025-03-15T17:30:50.625+0000] {processor.py:157} INFO - Started process (PID=2747) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:30:50.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:30:50.627+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:30:50.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:30:50.646+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:30:50.643+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:30:50.647+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:30:50.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.045 seconds
[2025-03-15T17:31:21.547+0000] {processor.py:157} INFO - Started process (PID=2757) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:31:21.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:31:21.550+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:31:21.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:31:21.572+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:31:21.569+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:31:21.573+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:31:21.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T17:31:52.450+0000] {processor.py:157} INFO - Started process (PID=2767) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:31:52.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:31:52.452+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:31:52.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:31:52.475+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:31:52.471+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:31:52.475+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:31:52.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.048 seconds
[2025-03-15T17:32:23.322+0000] {processor.py:157} INFO - Started process (PID=2777) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:32:23.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:32:23.323+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:32:23.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:32:23.341+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:32:23.338+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:32:23.342+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:32:23.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.048 seconds
[2025-03-15T17:32:54.121+0000] {processor.py:157} INFO - Started process (PID=2787) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:32:54.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:32:54.124+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:32:54.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:32:54.163+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:32:54.158+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:32:54.164+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:32:54.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.078 seconds
[2025-03-15T17:33:24.875+0000] {processor.py:157} INFO - Started process (PID=2797) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:33:24.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:33:24.878+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:33:24.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:33:24.897+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:33:24.894+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:33:24.897+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:33:24.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.046 seconds
[2025-03-15T17:33:55.896+0000] {processor.py:157} INFO - Started process (PID=2807) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:33:55.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:33:55.899+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:33:55.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:33:55.936+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:33:55.930+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:33:55.937+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:33:55.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.073 seconds
[2025-03-15T17:34:26.711+0000] {processor.py:157} INFO - Started process (PID=2817) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:34:26.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:34:26.714+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:34:26.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:34:26.741+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:34:26.737+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:34:26.742+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:34:26.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.069 seconds
[2025-03-15T17:34:57.419+0000] {processor.py:157} INFO - Started process (PID=2827) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:34:57.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:34:57.421+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:34:57.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:34:57.451+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:34:57.445+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:34:57.452+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:34:57.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.063 seconds
[2025-03-15T17:35:28.221+0000] {processor.py:157} INFO - Started process (PID=2837) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:35:28.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:35:28.224+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:35:28.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:35:28.250+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:35:28.245+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:35:28.251+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:35:28.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.059 seconds
[2025-03-15T17:35:58.963+0000] {processor.py:157} INFO - Started process (PID=2847) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:35:58.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:35:58.966+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:35:58.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:35:58.994+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:35:58.989+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:35:58.994+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:35:59.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.065 seconds
[2025-03-15T17:36:29.785+0000] {processor.py:157} INFO - Started process (PID=2857) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:36:29.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:36:29.787+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:36:29.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:36:29.809+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:36:29.805+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:36:29.809+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:36:29.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T17:37:00.725+0000] {processor.py:157} INFO - Started process (PID=2867) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:37:00.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:37:00.728+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:37:00.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:37:00.762+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:37:00.756+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:37:00.763+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:37:00.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.069 seconds
[2025-03-15T17:37:30.955+0000] {processor.py:157} INFO - Started process (PID=2877) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:37:30.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:37:30.958+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:37:30.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:37:30.992+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:37:30.986+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:37:30.993+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:37:31.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.066 seconds
[2025-03-15T17:38:01.899+0000] {processor.py:157} INFO - Started process (PID=2887) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:38:01.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:38:01.902+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:38:01.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:38:01.932+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:38:01.927+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:38:01.932+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:38:01.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.068 seconds
[2025-03-15T17:38:32.857+0000] {processor.py:157} INFO - Started process (PID=2897) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:38:32.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:38:32.860+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:38:32.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:38:32.886+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:38:32.880+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:38:32.886+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:38:32.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.068 seconds
[2025-03-15T17:39:03.787+0000] {processor.py:157} INFO - Started process (PID=2907) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:39:03.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:39:03.790+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:39:03.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:39:03.820+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:39:03.815+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:39:03.821+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:39:03.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.059 seconds
[2025-03-15T17:39:34.802+0000] {processor.py:157} INFO - Started process (PID=2917) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:39:34.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:39:34.804+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:39:34.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:39:34.820+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:39:34.818+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:39:34.821+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:39:34.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.046 seconds
[2025-03-15T17:40:05.678+0000] {processor.py:157} INFO - Started process (PID=2927) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:40:05.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:40:05.680+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:40:05.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:40:05.704+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:40:05.700+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:40:05.705+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:40:05.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.053 seconds
[2025-03-15T17:40:36.680+0000] {processor.py:157} INFO - Started process (PID=2937) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:40:36.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:40:36.682+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:40:36.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:40:36.700+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:40:36.696+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:40:36.700+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:40:36.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.044 seconds
[2025-03-15T17:53:21.734+0000] {processor.py:157} INFO - Started process (PID=2942) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:53:21.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:53:21.737+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:53:21.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:53:21.762+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:53:21.758+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:53:21.763+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:53:21.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.062 seconds
[2025-03-15T17:53:51.871+0000] {processor.py:157} INFO - Started process (PID=2954) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:53:51.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:53:51.873+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:53:51.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:53:51.897+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:53:51.892+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:53:51.898+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:53:51.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.054 seconds
[2025-03-15T17:54:22.854+0000] {processor.py:157} INFO - Started process (PID=2964) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:54:22.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:54:22.857+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:54:22.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:54:22.895+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:54:22.885+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:54:22.897+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:54:22.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.078 seconds
[2025-03-15T17:54:53.360+0000] {processor.py:157} INFO - Started process (PID=2974) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:54:53.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:54:53.363+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:54:53.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:54:53.390+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:54:53.384+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:54:53.391+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:54:53.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.062 seconds
[2025-03-15T17:55:23.837+0000] {processor.py:157} INFO - Started process (PID=2984) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:55:23.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:55:23.839+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:55:23.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:55:23.861+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:55:23.858+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:55:23.862+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:55:23.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.052 seconds
[2025-03-15T17:55:54.301+0000] {processor.py:157} INFO - Started process (PID=2994) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:55:54.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:55:54.303+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:55:54.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:55:54.326+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:55:54.323+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:55:54.327+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:55:54.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.053 seconds
[2025-03-15T17:56:24.752+0000] {processor.py:157} INFO - Started process (PID=3004) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:56:24.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:56:24.754+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:56:24.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:56:24.777+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:56:24.773+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:56:24.778+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:56:24.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.053 seconds
[2025-03-15T17:56:55.178+0000] {processor.py:157} INFO - Started process (PID=3014) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:56:55.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:56:55.181+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:56:55.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:56:55.207+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:56:55.202+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:56:55.208+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:56:55.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.057 seconds
[2025-03-15T17:57:25.516+0000] {processor.py:157} INFO - Started process (PID=3024) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:57:25.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:57:25.519+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:57:25.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:57:25.554+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:57:25.549+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:57:25.555+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:57:25.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.075 seconds
[2025-03-15T17:57:55.887+0000] {processor.py:157} INFO - Started process (PID=3034) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:57:55.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:57:55.891+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:57:55.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:57:55.928+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:57:55.922+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:57:55.928+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:57:55.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.082 seconds
[2025-03-15T17:58:26.214+0000] {processor.py:157} INFO - Started process (PID=3044) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:58:26.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:58:26.217+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:58:26.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:58:26.252+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:58:26.247+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:58:26.253+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:58:26.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.083 seconds
[2025-03-15T17:58:56.636+0000] {processor.py:157} INFO - Started process (PID=3054) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:58:56.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:58:56.638+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:58:56.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:58:56.660+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:58:56.656+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:58:56.661+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:58:56.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.054 seconds
[2025-03-15T17:59:27.091+0000] {processor.py:157} INFO - Started process (PID=3064) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:59:27.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:59:27.093+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:59:27.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:59:27.116+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:59:27.112+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:59:27.116+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:59:27.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.053 seconds
[2025-03-15T17:59:57.472+0000] {processor.py:157} INFO - Started process (PID=3074) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T17:59:57.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T17:59:57.474+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:59:57.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T17:59:57.498+0000] {logging_mixin.py:151} INFO - [2025-03-15T17:59:57.493+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T17:59:57.498+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T17:59:57.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.053 seconds
[2025-03-15T18:00:27.876+0000] {processor.py:157} INFO - Started process (PID=3084) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:00:27.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:00:27.878+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:00:27.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:00:27.899+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:00:27.895+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:00:27.900+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:00:27.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T18:00:58.294+0000] {processor.py:157} INFO - Started process (PID=3094) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:00:58.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:00:58.296+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:00:58.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:00:58.320+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:00:58.316+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:00:58.321+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:00:58.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.054 seconds
[2025-03-15T18:01:28.723+0000] {processor.py:157} INFO - Started process (PID=3104) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:01:28.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:01:28.725+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:01:28.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:01:28.750+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:01:28.745+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:01:28.751+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:01:28.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.061 seconds
[2025-03-15T18:01:59.119+0000] {processor.py:157} INFO - Started process (PID=3114) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:01:59.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:01:59.123+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:01:59.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:01:59.148+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:01:59.144+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:01:59.149+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:01:59.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.060 seconds
[2025-03-15T18:02:29.484+0000] {processor.py:157} INFO - Started process (PID=3124) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:02:29.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:02:29.486+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:02:29.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:02:29.517+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:02:29.512+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:02:29.518+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:02:29.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.062 seconds
[2025-03-15T18:02:59.852+0000] {processor.py:157} INFO - Started process (PID=3134) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:02:59.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:02:59.855+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:02:59.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:02:59.877+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:02:59.873+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:02:59.878+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:02:59.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.051 seconds
[2025-03-15T18:03:30.207+0000] {processor.py:157} INFO - Started process (PID=3144) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:03:30.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:03:30.210+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:03:30.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:03:30.235+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:03:30.231+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:03:30.235+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:03:30.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T18:04:00.644+0000] {processor.py:157} INFO - Started process (PID=3154) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:04:00.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:04:00.646+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:04:00.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:04:00.671+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:04:00.666+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:04:00.672+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:04:00.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T18:04:31.023+0000] {processor.py:157} INFO - Started process (PID=3164) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:04:31.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:04:31.025+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:04:31.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:04:31.049+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:04:31.045+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:04:31.050+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:04:31.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.056 seconds
[2025-03-15T18:05:01.599+0000] {processor.py:157} INFO - Started process (PID=3174) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:05:01.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:05:01.601+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:05:01.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:05:01.627+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:05:01.621+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:05:01.627+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:05:01.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T18:05:31.923+0000] {processor.py:157} INFO - Started process (PID=3184) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:05:31.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:05:31.926+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:05:31.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:05:31.963+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:05:31.956+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:05:31.963+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:05:31.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.074 seconds
[2025-03-15T18:06:02.314+0000] {processor.py:157} INFO - Started process (PID=3194) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:06:02.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:06:02.316+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:06:02.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:06:02.339+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:06:02.335+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:06:02.340+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:06:02.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.054 seconds
[2025-03-15T18:06:32.727+0000] {processor.py:157} INFO - Started process (PID=3204) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:06:32.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:06:32.729+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:06:32.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:06:32.756+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:06:32.750+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:06:32.756+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:06:32.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.059 seconds
[2025-03-15T18:07:03.545+0000] {processor.py:157} INFO - Started process (PID=3214) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:07:03.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:07:03.548+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:07:03.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:07:03.578+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:07:03.574+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:07:03.579+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:07:03.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.072 seconds
[2025-03-15T18:07:34.076+0000] {processor.py:157} INFO - Started process (PID=3224) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:07:34.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:07:34.078+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:07:34.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:07:34.106+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:07:34.101+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:07:34.107+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:07:34.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.059 seconds
[2025-03-15T18:08:05.114+0000] {processor.py:157} INFO - Started process (PID=3234) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:08:05.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:08:05.119+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:08:05.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:08:05.155+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:08:05.148+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:08:05.156+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:08:05.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.097 seconds
[2025-03-15T18:08:35.669+0000] {processor.py:157} INFO - Started process (PID=3244) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:08:35.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:08:35.674+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:08:35.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:08:35.709+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:08:35.703+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:08:35.710+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:08:35.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.072 seconds
[2025-03-15T18:09:06.607+0000] {processor.py:157} INFO - Started process (PID=3254) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:09:06.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:09:06.610+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:09:06.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:09:06.636+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:09:06.632+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:09:06.637+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:09:06.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.066 seconds
[2025-03-15T18:09:37.228+0000] {processor.py:157} INFO - Started process (PID=3264) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:09:37.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:09:37.231+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:09:37.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:09:37.259+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:09:37.254+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:09:37.260+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:09:37.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T18:10:07.793+0000] {processor.py:157} INFO - Started process (PID=3274) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:10:07.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:10:07.795+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:10:07.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:10:07.824+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:10:07.818+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:10:07.825+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:10:07.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T18:10:38.457+0000] {processor.py:157} INFO - Started process (PID=3284) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:10:38.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:10:38.461+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:10:38.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:10:38.496+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:10:38.490+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:10:38.497+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:10:38.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.089 seconds
[2025-03-15T18:11:08.808+0000] {processor.py:157} INFO - Started process (PID=3294) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:11:08.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:11:08.820+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:11:08.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:11:08.870+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:11:08.862+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:11:08.872+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:11:08.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.117 seconds
[2025-03-15T18:11:39.281+0000] {processor.py:157} INFO - Started process (PID=3304) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:11:39.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:11:39.298+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:11:39.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:11:39.361+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:11:39.353+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:11:39.362+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:11:39.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.153 seconds
[2025-03-15T18:12:09.508+0000] {processor.py:157} INFO - Started process (PID=3314) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:12:09.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:12:09.511+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:12:09.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:12:09.549+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:12:09.542+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:12:09.550+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:12:09.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.085 seconds
[2025-03-15T18:12:39.934+0000] {processor.py:157} INFO - Started process (PID=3324) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:12:39.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:12:39.937+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:12:39.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:12:39.975+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:12:39.968+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:12:39.975+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:12:40.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.082 seconds
[2025-03-15T18:13:10.277+0000] {processor.py:157} INFO - Started process (PID=3334) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:13:10.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:13:10.283+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:13:10.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:13:10.354+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:13:10.347+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:13:10.355+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:13:10.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.124 seconds
[2025-03-15T18:13:40.902+0000] {processor.py:157} INFO - Started process (PID=3344) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:13:40.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:13:40.905+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:13:40.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:13:40.932+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:13:40.927+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:13:40.932+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:13:40.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.063 seconds
[2025-03-15T18:14:11.598+0000] {processor.py:157} INFO - Started process (PID=3354) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:14:11.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:14:11.601+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:14:11.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:14:11.627+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:14:11.622+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:14:11.628+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:14:11.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.060 seconds
[2025-03-15T18:14:41.882+0000] {processor.py:157} INFO - Started process (PID=3364) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:14:41.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:14:41.887+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:14:41.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:14:41.917+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:14:41.912+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:14:41.918+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:14:41.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.072 seconds
[2025-03-15T18:15:12.338+0000] {processor.py:157} INFO - Started process (PID=3374) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T18:15:12.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T18:15:12.341+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:15:12.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T18:15:12.364+0000] {logging_mixin.py:151} INFO - [2025-03-15T18:15:12.360+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T18:15:12.365+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T18:15:12.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T19:44:37.528+0000] {processor.py:157} INFO - Started process (PID=164) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:44:37.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:44:37.533+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:44:37.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:44:37.602+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:44:37.592+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:44:37.603+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:44:37.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.135 seconds
[2025-03-15T19:45:08.228+0000] {processor.py:157} INFO - Started process (PID=174) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:45:08.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:45:08.232+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:45:08.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:45:08.283+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:45:08.276+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:45:08.284+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:45:08.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.107 seconds
[2025-03-15T19:45:38.610+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:45:38.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:45:38.616+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:45:38.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:45:38.659+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:45:38.654+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:45:38.660+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:45:38.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.106 seconds
[2025-03-15T19:46:09.123+0000] {processor.py:157} INFO - Started process (PID=194) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:46:09.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:46:09.128+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:46:09.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:46:09.172+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:46:09.164+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:46:09.173+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:46:09.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.093 seconds
[2025-03-15T19:46:39.423+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:46:39.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:46:39.426+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:46:39.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:46:39.489+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:46:39.478+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:46:39.490+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:46:39.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.116 seconds
[2025-03-15T19:47:09.946+0000] {processor.py:157} INFO - Started process (PID=214) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:47:09.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:47:09.950+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:47:09.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:47:10.001+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:47:09.991+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:47:10.002+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:47:10.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.108 seconds
[2025-03-15T19:47:40.351+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:47:40.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:47:40.357+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:47:40.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:47:40.423+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:47:40.412+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:47:40.424+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:47:40.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.137 seconds
[2025-03-15T19:48:10.820+0000] {processor.py:157} INFO - Started process (PID=234) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:48:10.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:48:10.824+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:48:10.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:48:11.366+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:48:11.358+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:48:11.368+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:48:11.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.603 seconds
[2025-03-15T19:48:41.931+0000] {processor.py:157} INFO - Started process (PID=244) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:48:41.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:48:41.933+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:48:41.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:48:41.964+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:48:41.959+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:48:41.965+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:48:41.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.067 seconds
[2025-03-15T19:49:12.314+0000] {processor.py:157} INFO - Started process (PID=254) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:49:12.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:49:12.317+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:49:12.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:49:12.364+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:49:12.356+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:49:12.365+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:49:12.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.093 seconds
[2025-03-15T19:49:42.751+0000] {processor.py:157} INFO - Started process (PID=264) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:49:42.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:49:42.754+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:49:42.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:49:42.795+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:49:42.787+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:49:42.796+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:49:42.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.083 seconds
[2025-03-15T19:50:13.204+0000] {processor.py:157} INFO - Started process (PID=274) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:50:13.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:50:13.207+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:50:13.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:50:13.241+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:50:13.234+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:50:13.242+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:50:13.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.083 seconds
[2025-03-15T19:50:43.542+0000] {processor.py:157} INFO - Started process (PID=284) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:50:43.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:50:43.545+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:50:43.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:50:41.562+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:50:41.553+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:50:41.563+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:50:41.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.103 seconds
[2025-03-15T19:51:12.022+0000] {processor.py:157} INFO - Started process (PID=294) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:12.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:12.025+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:12.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:12.069+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:12.052+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 72, in <module>
    upload_data_to_hdfs = BashOperator(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 150, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to BashOperator (task_id: upload_data_to_hdfs). Invalid arguments were:
**kwargs: {'provide_context': True}
[2025-03-15T19:51:12.072+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:12.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.103 seconds
[2025-03-15T19:51:40.620+0000] {processor.py:157} INFO - Started process (PID=304) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:40.624+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:40.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.691+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.100 seconds
[2025-03-15T19:51:40.767+0000] {processor.py:157} INFO - Started process (PID=309) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:40.770+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:40.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.791+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.045 seconds
[2025-03-15T19:51:40.856+0000] {processor.py:157} INFO - Started process (PID=314) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:40.858+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:40.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.874+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.043 seconds
[2025-03-15T19:51:40.951+0000] {processor.py:157} INFO - Started process (PID=319) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:40.953+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:40.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.971+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:40.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.040 seconds
[2025-03-15T19:51:41.035+0000] {processor.py:157} INFO - Started process (PID=324) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:41.037+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:41.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.052+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.040 seconds
[2025-03-15T19:51:41.135+0000] {processor.py:157} INFO - Started process (PID=329) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:41.140+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:41.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.161+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.059 seconds
[2025-03-15T19:51:41.248+0000] {processor.py:157} INFO - Started process (PID=334) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:41.250+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:41.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.270+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.044 seconds
[2025-03-15T19:51:41.358+0000] {processor.py:157} INFO - Started process (PID=339) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:41.363+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:41.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.389+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.060 seconds
[2025-03-15T19:51:41.462+0000] {processor.py:157} INFO - Started process (PID=344) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:41.465+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:41.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.483+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.045 seconds
[2025-03-15T19:51:41.558+0000] {processor.py:157} INFO - Started process (PID=349) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:41.561+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:41.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.590+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.057 seconds
[2025-03-15T19:51:41.675+0000] {processor.py:157} INFO - Started process (PID=354) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:41.677+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:41.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.693+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.037 seconds
[2025-03-15T19:51:41.770+0000] {processor.py:157} INFO - Started process (PID=359) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:41.774+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:41.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.799+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:41.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.051 seconds
[2025-03-15T19:51:50.019+0000] {processor.py:157} INFO - Started process (PID=369) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:50.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:50.022+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:50.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:50.074+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:50.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.077 seconds
[2025-03-15T19:51:50.162+0000] {processor.py:157} INFO - Started process (PID=374) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:50.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:50.167+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:50.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:50.197+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:50.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.069 seconds
[2025-03-15T19:51:50.294+0000] {processor.py:157} INFO - Started process (PID=379) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:50.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:50.297+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:50.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:50.317+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:50.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.054 seconds
[2025-03-15T19:51:54.395+0000] {processor.py:157} INFO - Started process (PID=384) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:54.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:54.397+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:54.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:54.438+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:54.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.066 seconds
[2025-03-15T19:51:55.480+0000] {processor.py:157} INFO - Started process (PID=389) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:55.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:55.482+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:55.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:55.525+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:55.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T19:51:55.591+0000] {processor.py:157} INFO - Started process (PID=394) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:55.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:55.594+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:55.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:55.617+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:55.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.052 seconds
[2025-03-15T19:51:55.703+0000] {processor.py:157} INFO - Started process (PID=399) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:55.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:55.706+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:55.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:55.729+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:55.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T19:51:59.803+0000] {processor.py:157} INFO - Started process (PID=404) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:59.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:51:59.805+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:51:59.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:59.847+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:51:59.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.062 seconds
[2025-03-15T19:52:01.895+0000] {processor.py:157} INFO - Started process (PID=409) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:01.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:52:01.898+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:01.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:01.947+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:01.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.081 seconds
[2025-03-15T19:52:05.017+0000] {processor.py:157} INFO - Started process (PID=414) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:05.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:52:05.021+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:05.059+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.056+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 846, in exec_module
  File "<frozen importlib._bootstrap_external>", line 983, in get_code
  File "<frozen importlib._bootstrap_external>", line 913, in source_to_code
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 84
    "
     ^
SyntaxError: EOL while scanning string literal
[2025-03-15T19:52:05.061+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:05.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.082 seconds
[2025-03-15T19:52:07.213+0000] {processor.py:157} INFO - Started process (PID=419) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:07.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:52:07.216+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:07.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:07.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:05.533+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.532+0000] {manager.py:501} INFO - Created Permission View: can delete on DAG:csv_to_hdfs_ingestion
[2025-03-15T19:52:05.551+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.550+0000] {manager.py:501} INFO - Created Permission View: can edit on DAG:csv_to_hdfs_ingestion
[2025-03-15T19:52:05.561+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.561+0000] {manager.py:501} INFO - Created Permission View: can read on DAG:csv_to_hdfs_ingestion
[2025-03-15T19:52:05.578+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.578+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:52:05.592+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.592+0000] {dag.py:2929} INFO - Creating ORM DAG for csv_to_hdfs_ingestion
[2025-03-15T19:52:05.605+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.605+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:52:05.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.447 seconds
[2025-03-15T19:52:05.696+0000] {processor.py:157} INFO - Started process (PID=424) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:05.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:52:05.699+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:05.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:05.754+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.753+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:52:05.781+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.781+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:52:05.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.121 seconds
[2025-03-15T19:52:05.869+0000] {processor.py:157} INFO - Started process (PID=429) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:05.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:52:05.872+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:05.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:05.919+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.919+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:52:05.945+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:05.944+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:52:05.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.107 seconds
[2025-03-15T19:52:06.035+0000] {processor.py:157} INFO - Started process (PID=434) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:52:06.038+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.094+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.094+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:52:06.118+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.118+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:52:06.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.112 seconds
[2025-03-15T19:52:06.193+0000] {processor.py:157} INFO - Started process (PID=439) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:52:06.195+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.246+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.245+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:52:06.272+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.272+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:52:06.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.109 seconds
[2025-03-15T19:52:06.355+0000] {processor.py:157} INFO - Started process (PID=444) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:52:06.357+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.403+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.403+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:52:06.427+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.427+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:52:06.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.101 seconds
[2025-03-15T19:52:06.504+0000] {processor.py:157} INFO - Started process (PID=449) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:52:06.506+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:06.550+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.550+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:52:06.575+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:06.574+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:52:06.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.097 seconds
[2025-03-15T19:52:36.903+0000] {processor.py:157} INFO - Started process (PID=459) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:36.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:52:36.910+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:36.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:36.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:52:36.978+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:36.978+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:52:37.014+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:52:37.014+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:52:37.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.175 seconds
[2025-03-15T19:53:07.456+0000] {processor.py:157} INFO - Started process (PID=469) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:53:07.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:53:07.460+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:53:07.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:53:07.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:53:07.572+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:53:07.572+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:53:07.626+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:53:07.626+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:53:07.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.236 seconds
[2025-03-15T19:53:37.809+0000] {processor.py:157} INFO - Started process (PID=479) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:53:37.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:53:37.812+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:53:37.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:53:37.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:53:37.894+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:53:37.894+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:53:37.921+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:53:37.920+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:53:37.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.150 seconds
[2025-03-15T19:54:08.195+0000] {processor.py:157} INFO - Started process (PID=489) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:54:08.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:54:08.198+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:54:08.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:54:08.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:54:08.267+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:54:08.266+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:54:08.294+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:54:08.294+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:54:08.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.133 seconds
[2025-03-15T19:54:38.615+0000] {processor.py:157} INFO - Started process (PID=499) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:54:38.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:54:38.617+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:54:38.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:54:38.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:54:38.680+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:54:38.680+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:54:38.708+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:54:38.707+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:54:38.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.131 seconds
[2025-03-15T19:55:08.985+0000] {processor.py:157} INFO - Started process (PID=509) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:55:08.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:55:08.988+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:55:08.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:55:09.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:55:09.162+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:55:09.162+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:55:09.211+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:55:09.210+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:55:09.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.269 seconds
[2025-03-15T19:55:39.719+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:55:39.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:55:39.733+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:55:39.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:55:39.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:55:39.853+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:55:39.853+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:55:39.885+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:55:39.885+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:55:39.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.218 seconds
[2025-03-15T19:56:10.089+0000] {processor.py:157} INFO - Started process (PID=529) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:56:10.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:56:10.099+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:56:10.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:56:10.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:56:10.297+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:56:10.297+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:56:10.395+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:56:10.395+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:56:10.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.405 seconds
[2025-03-15T19:56:40.750+0000] {processor.py:157} INFO - Started process (PID=539) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:56:40.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:56:40.762+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:56:40.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:56:40.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:56:41.049+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:56:41.048+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:56:41.141+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:56:41.140+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:56:41.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.491 seconds
[2025-03-15T19:57:12.036+0000] {processor.py:157} INFO - Started process (PID=549) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:57:12.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:57:12.038+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:57:12.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:57:12.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:57:12.097+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:57:12.096+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:57:12.132+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:57:12.131+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:57:12.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.133 seconds
[2025-03-15T19:57:42.925+0000] {processor.py:157} INFO - Started process (PID=559) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T19:57:42.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T19:57:42.929+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:57:42.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T19:57:42.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T19:57:43.018+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:57:43.018+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T19:57:43.065+0000] {logging_mixin.py:151} INFO - [2025-03-15T19:57:43.065+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T19:57:43.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.186 seconds
[2025-03-15T20:03:44.193+0000] {processor.py:157} INFO - Started process (PID=164) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:03:44.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:03:44.197+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:03:44.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:03:44.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:03:44.272+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:03:44.271+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:03:44.324+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:03:44.323+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:03:44.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.205 seconds
[2025-03-15T20:04:14.993+0000] {processor.py:157} INFO - Started process (PID=174) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:04:14.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:04:14.997+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:04:14.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:04:15.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:04:15.115+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:04:15.114+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:04:15.152+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:04:15.152+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:04:15.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.191 seconds
[2025-03-15T20:04:46.014+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:04:46.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:04:46.017+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:04:46.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:04:46.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:04:46.098+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:04:46.097+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:04:46.126+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:04:46.126+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:04:46.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.139 seconds
[2025-03-15T20:05:16.928+0000] {processor.py:157} INFO - Started process (PID=200) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:05:16.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:05:16.932+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:05:16.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:05:16.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:05:17.048+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:05:17.048+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:05:17.087+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:05:17.086+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:05:17.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.190 seconds
[2025-03-15T20:05:47.908+0000] {processor.py:157} INFO - Started process (PID=211) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:05:47.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:05:47.912+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:05:47.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:05:47.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:05:48.003+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:05:48.002+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:05:48.040+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:05:48.039+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:05:48.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.360 seconds
[2025-03-15T20:06:18.812+0000] {processor.py:157} INFO - Started process (PID=225) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:06:18.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:06:18.819+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:06:18.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:06:18.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:06:19.054+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:06:19.054+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:06:19.712+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:06:19.711+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:06:19.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.982 seconds
[2025-03-15T20:06:50.706+0000] {processor.py:157} INFO - Started process (PID=240) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:06:50.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:06:50.717+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:06:50.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:06:50.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:06:50.953+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:06:50.952+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:06:51.629+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:06:51.629+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:06:51.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.974 seconds
[2025-03-15T20:07:21.813+0000] {processor.py:157} INFO - Started process (PID=268) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:07:21.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:07:21.817+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:07:21.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:07:22.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:07:22.192+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:07:22.192+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:07:22.235+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:07:22.235+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:07:22.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.460 seconds
[2025-03-15T20:07:52.697+0000] {processor.py:157} INFO - Started process (PID=278) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:07:52.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:07:52.700+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:07:52.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:07:52.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:07:52.806+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:07:52.803+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:07:52.876+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:07:52.875+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:07:52.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.224 seconds
[2025-03-15T20:08:23.684+0000] {processor.py:157} INFO - Started process (PID=288) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:08:23.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:08:23.686+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:08:23.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:08:23.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:08:23.754+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:08:23.751+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:08:23.756+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:08:23.755+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:08:23.789+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:08:23.789+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:08:23.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.142 seconds
[2025-03-15T20:08:54.626+0000] {processor.py:157} INFO - Started process (PID=298) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:08:54.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:08:54.628+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:08:54.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:08:54.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:08:54.687+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:08:54.685+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:08:54.688+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:08:54.688+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:08:54.713+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:08:54.712+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:08:54.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.118 seconds
[2025-03-15T20:09:25.515+0000] {processor.py:157} INFO - Started process (PID=308) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:09:25.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:09:25.518+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:09:25.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:09:25.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:09:25.582+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:09:25.579+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:09:25.584+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:09:25.584+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:09:25.607+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:09:25.607+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:09:25.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.125 seconds
[2025-03-15T20:09:56.437+0000] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:09:56.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:09:56.441+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:09:56.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:09:56.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:09:56.513+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:09:56.510+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:09:56.515+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:09:56.515+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:09:56.540+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:09:56.540+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:09:56.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.142 seconds
[2025-03-15T20:10:27.394+0000] {processor.py:157} INFO - Started process (PID=328) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:10:27.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:10:27.397+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:10:27.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:10:27.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:10:27.464+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:10:27.462+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:10:27.466+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:10:27.466+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:10:27.494+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:10:27.493+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:10:27.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.138 seconds
[2025-03-15T20:10:57.709+0000] {processor.py:157} INFO - Started process (PID=338) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:10:57.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:10:57.712+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:10:57.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:10:57.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:10:57.766+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:10:57.764+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:10:57.768+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:10:57.768+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:10:57.797+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:10:57.797+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:10:57.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.119 seconds
[2025-03-15T20:11:28.693+0000] {processor.py:157} INFO - Started process (PID=348) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:11:28.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:11:28.699+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:11:28.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:11:28.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:11:28.802+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:11:28.794+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:11:28.804+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:11:28.804+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:11:28.852+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:11:28.852+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:11:28.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.212 seconds
[2025-03-15T20:11:59.609+0000] {processor.py:157} INFO - Started process (PID=358) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:11:59.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:11:59.612+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:11:59.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:11:59.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:11:59.685+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:11:59.683+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:11:59.686+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:11:59.686+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:11:59.715+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:11:59.714+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:11:59.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.143 seconds
[2025-03-15T20:12:30.691+0000] {processor.py:157} INFO - Started process (PID=368) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:12:30.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:12:30.694+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:12:30.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:12:30.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:12:30.774+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:12:30.771+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:12:30.776+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:12:30.776+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:12:30.811+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:12:30.811+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:12:30.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.168 seconds
[2025-03-15T20:13:01.559+0000] {processor.py:157} INFO - Started process (PID=378) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:01.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:01.562+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:01.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:01.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:01.622+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:01.619+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:13:01.623+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:01.623+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:13:01.649+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:01.649+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:13:01.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.127 seconds
[2025-03-15T20:13:15.236+0000] {processor.py:157} INFO - Started process (PID=383) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:15.239+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:15.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.290+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.081 seconds
[2025-03-15T20:13:15.381+0000] {processor.py:157} INFO - Started process (PID=388) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:15.384+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:15.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.405+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.044 seconds
[2025-03-15T20:13:15.479+0000] {processor.py:157} INFO - Started process (PID=393) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:15.482+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:15.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.504+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.048 seconds
[2025-03-15T20:13:15.587+0000] {processor.py:157} INFO - Started process (PID=398) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:15.591+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:15.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.619+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.056 seconds
[2025-03-15T20:13:15.697+0000] {processor.py:157} INFO - Started process (PID=403) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:15.699+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:15.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.721+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.044 seconds
[2025-03-15T20:13:15.785+0000] {processor.py:157} INFO - Started process (PID=408) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:15.787+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:15.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.804+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.042 seconds
[2025-03-15T20:13:15.883+0000] {processor.py:157} INFO - Started process (PID=413) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:15.886+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:15.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.903+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.039 seconds
[2025-03-15T20:13:15.965+0000] {processor.py:157} INFO - Started process (PID=418) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:15.968+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:15.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:15.985+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.041 seconds
[2025-03-15T20:13:16.053+0000] {processor.py:157} INFO - Started process (PID=423) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:16.056+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:16.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.075+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.044 seconds
[2025-03-15T20:13:16.150+0000] {processor.py:157} INFO - Started process (PID=428) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:16.153+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:16.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.176+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.056 seconds
[2025-03-15T20:13:16.277+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:16.281+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:16.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.298+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.049 seconds
[2025-03-15T20:13:16.381+0000] {processor.py:157} INFO - Started process (PID=438) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:16.384+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:16.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.404+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T20:13:16.483+0000] {processor.py:157} INFO - Started process (PID=443) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:16.487+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:16.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.507+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.054 seconds
[2025-03-15T20:13:16.590+0000] {processor.py:157} INFO - Started process (PID=448) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:16.594+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:16.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.614+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.051 seconds
[2025-03-15T20:13:16.696+0000] {processor.py:157} INFO - Started process (PID=453) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:16.700+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:16.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.720+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.053 seconds
[2025-03-15T20:13:16.805+0000] {processor.py:157} INFO - Started process (PID=458) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:16.808+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:16.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.827+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:16.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.050 seconds
[2025-03-15T20:13:47.871+0000] {processor.py:157} INFO - Started process (PID=468) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:47.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:13:47.873+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:13:47.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:47.899+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:13:47.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.048 seconds
[2025-03-15T20:14:02.254+0000] {processor.py:157} INFO - Started process (PID=473) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:14:02.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:14:02.257+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:14:02.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:14:02.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:14:02.355+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:14:02.351+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:14:02.356+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:14:02.356+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:14:02.396+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:14:02.396+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:14:02.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.179 seconds
[2025-03-15T20:14:33.198+0000] {processor.py:157} INFO - Started process (PID=483) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:14:33.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:14:33.201+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:14:33.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:14:33.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:14:33.295+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:14:33.290+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:14:33.296+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:14:33.296+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:14:33.328+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:14:33.328+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:14:33.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.164 seconds
[2025-03-15T20:15:03.492+0000] {processor.py:157} INFO - Started process (PID=493) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:15:03.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:15:03.495+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:15:03.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:15:03.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:15:03.559+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:15:03.556+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:15:03.561+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:15:03.561+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:15:03.598+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:15:03.598+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:15:03.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.142 seconds
[2025-03-15T20:15:34.509+0000] {processor.py:157} INFO - Started process (PID=503) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:15:34.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:15:34.514+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:15:34.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:15:34.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:15:34.594+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:15:34.590+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:15:34.596+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:15:34.596+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:15:34.638+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:15:34.638+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:15:34.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.175 seconds
[2025-03-15T20:16:05.331+0000] {processor.py:157} INFO - Started process (PID=513) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:16:05.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:16:05.336+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:16:05.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:16:05.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:16:05.438+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:16:05.433+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    for subdag in dag.subdags:
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 74, in wrapper
    session_args_idx = tuple(func_params).index("session")
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 156, in write_dag
    # Checks if (Current Time - Time when the DAG was written to DB) < min_update_interval
  File "<string>", line 4, in __init__
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 482, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/serialized_dag.py", line 103, in __init__
    innerjoin=True,
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 1381, in to_dict
    setattr(task, date_attr, getattr(dag, date_attr, None))
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/serialization/serialized_objects.py", line 332, in validate_schema
  File "/home/airflow/.local/lib/python3.9/site-packages/jsonschema/validators.py", line 435, in validate
    raise error
jsonschema.exceptions.ValidationError: {} is not of type 'array'

Failed validating 'type' in schema['allOf'][0]['properties']['dag']['properties']['params']:
    {'prefixItems': [{'type': 'string'}, {'$ref': '#/definitions/param'}],
     'type': 'array',
     'unevaluatedItems': False}

On instance['dag']['params']:
    {}
[2025-03-15T20:16:05.441+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:16:05.441+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:16:05.484+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:16:05.484+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:16:05.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.198 seconds
[2025-03-15T20:31:46.821+0000] {processor.py:157} INFO - Started process (PID=164) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:31:46.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:31:46.826+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:31:46.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:31:46.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:31:46.893+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:31:46.892+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:31:46.933+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:31:46.933+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:31:46.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.147 seconds
[2025-03-15T20:32:17.301+0000] {processor.py:157} INFO - Started process (PID=174) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:32:17.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:32:17.306+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:32:17.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:32:17.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:32:17.432+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:32:17.432+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:32:17.465+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:32:17.465+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:32:17.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.192 seconds
[2025-03-15T20:32:47.564+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:32:47.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:32:47.570+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:32:47.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:32:47.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:32:47.672+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:32:47.672+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:32:47.710+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:32:47.710+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:32:47.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.179 seconds
[2025-03-15T20:33:18.627+0000] {processor.py:157} INFO - Started process (PID=194) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:33:18.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:33:18.631+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:33:18.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:33:18.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:33:18.692+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:33:18.691+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:33:18.723+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:33:18.723+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:33:18.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.119 seconds
[2025-03-15T20:33:49.548+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:33:49.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:33:49.553+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:33:49.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:33:49.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:33:49.674+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:33:49.673+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:33:49.701+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:33:49.701+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:33:49.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.193 seconds
[2025-03-15T20:34:20.631+0000] {processor.py:157} INFO - Started process (PID=214) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:34:20.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:34:20.634+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:34:20.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:34:20.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:34:20.700+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:34:20.699+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:34:20.736+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:34:20.736+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:34:20.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.285 seconds
[2025-03-15T20:34:51.547+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:34:51.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:34:51.549+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:34:51.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:34:51.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:34:51.617+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:34:51.616+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:34:51.774+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:34:51.774+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:34:51.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.264 seconds
[2025-03-15T20:35:22.711+0000] {processor.py:157} INFO - Started process (PID=239) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:35:22.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:35:22.714+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:35:22.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:35:22.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:35:22.778+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:35:22.777+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:35:23.013+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:35:23.012+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:35:23.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.327 seconds
[2025-03-15T20:35:53.921+0000] {processor.py:157} INFO - Started process (PID=249) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:35:53.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:35:53.926+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:35:53.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:35:54.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:35:54.168+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:35:54.168+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:35:54.198+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:35:54.198+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:35:54.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.312 seconds
[2025-03-15T20:36:24.695+0000] {processor.py:157} INFO - Started process (PID=259) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:36:24.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:36:24.698+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:36:24.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:36:24.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:36:24.812+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:36:24.812+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:36:24.844+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:36:24.844+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:36:24.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.188 seconds
[2025-03-15T20:36:54.969+0000] {processor.py:157} INFO - Started process (PID=269) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:36:54.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:36:54.988+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:36:54.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:36:55.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:36:55.289+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:36:55.289+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:36:55.381+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:36:55.380+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:36:55.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.481 seconds
[2025-03-15T20:37:26.371+0000] {processor.py:157} INFO - Started process (PID=279) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:37:26.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:37:26.375+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:37:26.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:37:26.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:37:26.459+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:37:26.458+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:37:26.496+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:37:26.496+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:37:26.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.161 seconds
[2025-03-15T20:37:57.365+0000] {processor.py:157} INFO - Started process (PID=289) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:37:57.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:37:57.369+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:37:57.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:37:57.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:37:57.437+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:37:57.437+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:37:57.466+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:37:57.466+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:37:57.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.135 seconds
[2025-03-15T20:38:28.275+0000] {processor.py:157} INFO - Started process (PID=299) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:38:28.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:38:28.278+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:38:28.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:38:28.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:38:28.338+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:38:28.338+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:38:28.363+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:38:28.363+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:38:28.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.114 seconds
[2025-03-15T20:38:59.216+0000] {processor.py:157} INFO - Started process (PID=309) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:38:59.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:38:59.220+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:38:59.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:38:59.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:38:59.299+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:38:59.298+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:38:59.330+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:38:59.330+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:38:59.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.153 seconds
[2025-03-15T20:39:29.995+0000] {processor.py:157} INFO - Started process (PID=319) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:39:29.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:39:29.999+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:39:29.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:39:30.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:39:30.170+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:39:30.170+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:39:30.246+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:39:30.246+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:39:30.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.302 seconds
[2025-03-15T20:40:01.066+0000] {processor.py:157} INFO - Started process (PID=329) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:40:01.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:40:01.070+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:40:01.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:40:01.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:40:01.136+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:40:01.136+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:40:01.177+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:40:01.177+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:40:01.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.153 seconds
[2025-03-15T20:40:31.368+0000] {processor.py:157} INFO - Started process (PID=339) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:40:31.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:40:31.373+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:40:31.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:40:31.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:40:31.456+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:40:31.456+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:40:31.494+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:40:31.493+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:40:31.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.170 seconds
[2025-03-15T20:41:02.178+0000] {processor.py:157} INFO - Started process (PID=349) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:41:02.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:41:02.180+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:41:02.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:41:02.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:41:02.224+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:41:02.223+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:41:02.248+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:41:02.248+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:41:02.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.092 seconds
[2025-03-15T20:41:33.161+0000] {processor.py:157} INFO - Started process (PID=359) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:41:33.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:41:33.164+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:41:33.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:41:33.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:41:33.220+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:41:33.220+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:41:33.243+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:41:33.242+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:41:33.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.112 seconds
[2025-03-15T20:42:04.056+0000] {processor.py:157} INFO - Started process (PID=369) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:42:04.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:42:04.058+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:42:04.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:42:04.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:42:04.132+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:42:04.131+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:42:04.167+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:42:04.166+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:42:04.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.150 seconds
[2025-03-15T20:42:34.912+0000] {processor.py:157} INFO - Started process (PID=379) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:42:34.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:42:34.916+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:42:34.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:42:34.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:42:34.992+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:42:34.992+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:42:35.022+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:42:35.021+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:42:35.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.141 seconds
[2025-03-15T20:43:05.790+0000] {processor.py:157} INFO - Started process (PID=389) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:43:05.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:43:05.792+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:43:05.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:43:05.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:43:05.860+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:43:05.860+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:43:05.889+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:43:05.889+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:43:05.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.134 seconds
[2025-03-15T20:43:36.537+0000] {processor.py:157} INFO - Started process (PID=399) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:43:36.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:43:36.541+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:43:36.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:43:36.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:43:36.632+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:43:36.632+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:43:36.707+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:43:36.706+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:43:36.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.232 seconds
[2025-03-15T20:44:07.544+0000] {processor.py:157} INFO - Started process (PID=409) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:44:07.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:44:07.547+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:44:07.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:44:07.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:44:07.604+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:44:07.604+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:44:07.636+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:44:07.636+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:44:07.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.123 seconds
[2025-03-15T20:44:37.803+0000] {processor.py:157} INFO - Started process (PID=419) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:44:37.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:44:37.807+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:44:37.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:44:37.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:44:37.949+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:44:37.948+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:44:38.063+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:44:38.062+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:44:38.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.368 seconds
[2025-03-15T20:45:08.642+0000] {processor.py:157} INFO - Started process (PID=429) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:45:08.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:45:08.645+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:45:08.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:45:08.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:45:08.737+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:45:08.736+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:45:08.784+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:45:08.784+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:45:08.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.181 seconds
[2025-03-15T20:45:39.599+0000] {processor.py:157} INFO - Started process (PID=439) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:45:39.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:45:39.601+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:45:39.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:45:39.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:45:39.674+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:45:39.674+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:45:39.715+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:45:39.715+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:45:39.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.152 seconds
[2025-03-15T20:46:10.485+0000] {processor.py:157} INFO - Started process (PID=449) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:46:10.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:46:10.488+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:46:10.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:46:10.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:46:10.558+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:46:10.558+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:46:10.595+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:46:10.595+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:46:10.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.147 seconds
[2025-03-15T20:46:41.461+0000] {processor.py:157} INFO - Started process (PID=459) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:46:41.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:46:41.465+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:46:41.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:46:41.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:46:41.551+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:46:41.551+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:46:41.584+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:46:41.583+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:46:41.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.158 seconds
[2025-03-15T20:47:12.320+0000] {processor.py:157} INFO - Started process (PID=469) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:47:12.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:47:12.323+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:47:12.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:47:12.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:47:12.394+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:47:12.394+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:47:12.418+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:47:12.418+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:47:12.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.127 seconds
[2025-03-15T20:47:43.290+0000] {processor.py:157} INFO - Started process (PID=479) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:47:43.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:47:43.293+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:47:43.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:47:43.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:47:43.357+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:47:43.357+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:47:43.382+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:47:43.382+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:47:43.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.123 seconds
[2025-03-15T20:48:14.234+0000] {processor.py:157} INFO - Started process (PID=489) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:48:14.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:48:14.238+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:48:14.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:48:14.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:48:14.334+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:48:14.333+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:48:14.358+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:48:14.358+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:48:14.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.159 seconds
[2025-03-15T20:48:44.453+0000] {processor.py:157} INFO - Started process (PID=499) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:48:44.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:48:44.457+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:48:44.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:48:44.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:48:44.540+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:48:44.540+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:48:44.579+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:48:44.578+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:48:44.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.172 seconds
[2025-03-15T20:49:15.290+0000] {processor.py:157} INFO - Started process (PID=509) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:49:15.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:49:15.294+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:49:15.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:49:15.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:49:15.439+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:49:15.439+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:49:15.511+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:49:15.510+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:49:15.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.271 seconds
[2025-03-15T20:49:45.983+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:49:45.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:49:45.987+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:49:45.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:49:46.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:49:46.116+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:49:46.116+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:49:46.244+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:49:46.243+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:49:46.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.344 seconds
[2025-03-15T20:50:17.134+0000] {processor.py:157} INFO - Started process (PID=529) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:50:17.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:50:17.137+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:50:17.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:50:17.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:50:17.238+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:50:17.238+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:50:17.280+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:50:17.279+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:50:17.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.183 seconds
[2025-03-15T20:50:48.034+0000] {processor.py:157} INFO - Started process (PID=539) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:50:48.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:50:48.038+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:50:48.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:50:48.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:50:48.156+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:50:48.156+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:50:48.194+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:50:48.194+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:50:48.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.210 seconds
[2025-03-15T20:51:18.533+0000] {processor.py:157} INFO - Started process (PID=549) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:51:18.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:51:18.536+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:51:18.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:51:18.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:51:18.628+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:51:18.628+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:51:18.665+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:51:18.665+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:51:18.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.167 seconds
[2025-03-15T20:51:49.024+0000] {processor.py:157} INFO - Started process (PID=559) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:51:49.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:51:49.027+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:51:49.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:51:49.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:51:49.092+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:51:49.091+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:51:49.132+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:51:49.132+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:51:49.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.150 seconds
[2025-03-15T20:52:19.873+0000] {processor.py:157} INFO - Started process (PID=569) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:52:19.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:52:19.878+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:52:19.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:52:19.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:52:19.959+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:52:19.958+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:52:20.001+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:52:20.001+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:52:20.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.169 seconds
[2025-03-15T20:52:50.107+0000] {processor.py:157} INFO - Started process (PID=579) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:52:50.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:52:50.113+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:52:50.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:52:50.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:52:50.198+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:52:50.197+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:52:50.235+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:52:50.235+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:52:50.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.184 seconds
[2025-03-15T20:53:21.025+0000] {processor.py:157} INFO - Started process (PID=589) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:53:21.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:53:21.028+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:53:21.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:53:21.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:53:21.108+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:53:21.107+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:53:21.156+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:53:21.156+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:53:21.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.168 seconds
[2025-03-15T20:53:51.793+0000] {processor.py:157} INFO - Started process (PID=599) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:53:51.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:53:51.796+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:53:51.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:53:51.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:53:51.864+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:53:51.864+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:53:51.901+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:53:51.901+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:53:51.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.150 seconds
[2025-03-15T20:54:22.617+0000] {processor.py:157} INFO - Started process (PID=609) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:54:22.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:54:22.621+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:54:22.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:54:22.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:54:22.703+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:54:22.703+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:54:22.737+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:54:22.737+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:54:22.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.158 seconds
[2025-03-15T20:54:53.556+0000] {processor.py:157} INFO - Started process (PID=619) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:54:53.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:54:53.560+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:54:53.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:54:53.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:54:53.640+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:54:53.640+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:54:53.675+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:54:53.675+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:54:53.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.155 seconds
[2025-03-15T20:55:24.475+0000] {processor.py:157} INFO - Started process (PID=629) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:55:24.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:55:24.478+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:55:24.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:55:24.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:55:24.573+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:55:24.572+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:55:24.621+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:55:24.620+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:55:24.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.181 seconds
[2025-03-15T20:55:55.496+0000] {processor.py:157} INFO - Started process (PID=639) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T20:55:55.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T20:55:55.499+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:55:55.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T20:55:55.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T20:55:55.551+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:55:55.550+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T20:55:55.578+0000] {logging_mixin.py:151} INFO - [2025-03-15T20:55:55.578+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T20:55:55.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.113 seconds
[2025-03-15T21:11:41.602+0000] {processor.py:157} INFO - Started process (PID=163) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:11:41.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:11:41.611+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:11:41.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:11:41.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:11:42.426+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:11:42.425+0000] {manager.py:501} INFO - Created Permission View: can edit on DAG:csv_to_hdfs_ingestion
[2025-03-15T21:11:42.445+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:11:42.444+0000] {manager.py:501} INFO - Created Permission View: can delete on DAG:csv_to_hdfs_ingestion
[2025-03-15T21:11:42.466+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:11:42.466+0000] {manager.py:501} INFO - Created Permission View: can read on DAG:csv_to_hdfs_ingestion
[2025-03-15T21:11:42.505+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:11:42.505+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:11:42.542+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:11:42.541+0000] {dag.py:2929} INFO - Creating ORM DAG for csv_to_hdfs_ingestion
[2025-03-15T21:11:42.873+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:11:42.872+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:11:42.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 1.336 seconds
[2025-03-15T21:12:13.676+0000] {processor.py:157} INFO - Started process (PID=178) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:12:13.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:12:13.680+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:12:13.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:12:13.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:12:13.768+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:12:13.768+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:12:13.874+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:12:13.873+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:12:13.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.280 seconds
[2025-03-15T21:12:44.525+0000] {processor.py:157} INFO - Started process (PID=188) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:12:44.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:12:44.528+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:12:44.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:12:44.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:12:44.589+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:12:44.588+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:12:44.626+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:12:44.626+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:12:44.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.134 seconds
[2025-03-15T21:13:15.252+0000] {processor.py:157} INFO - Started process (PID=198) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:13:15.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:13:15.254+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:13:15.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:13:15.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:13:15.325+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:13:15.325+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:13:15.366+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:13:15.366+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:13:15.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.144 seconds
[2025-03-15T21:13:46.300+0000] {processor.py:157} INFO - Started process (PID=208) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:13:46.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:13:46.303+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:13:46.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:13:46.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:13:46.377+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:13:46.377+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:13:46.407+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:13:46.406+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:13:46.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.149 seconds
[2025-03-15T21:14:17.037+0000] {processor.py:157} INFO - Started process (PID=218) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:14:17.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:14:17.039+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:14:17.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:14:17.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:14:17.108+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:14:17.108+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:14:17.334+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:14:17.334+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:14:17.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.321 seconds
[2025-03-15T21:14:48.032+0000] {processor.py:157} INFO - Started process (PID=228) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:14:48.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:14:48.034+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:14:48.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:14:48.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:14:48.095+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:14:48.095+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:14:48.281+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:14:48.281+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:14:48.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.282 seconds
[2025-03-15T21:15:18.795+0000] {processor.py:157} INFO - Started process (PID=238) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:15:18.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:15:18.797+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:15:18.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:15:18.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:15:19.016+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:15:19.015+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:15:19.057+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:15:19.057+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:15:19.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.291 seconds
[2025-03-15T21:15:49.387+0000] {processor.py:157} INFO - Started process (PID=248) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:15:49.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:15:49.391+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:15:49.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:15:49.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:15:49.655+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:15:49.654+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:15:49.707+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:15:49.706+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:15:49.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.358 seconds
[2025-03-15T21:16:20.556+0000] {processor.py:157} INFO - Started process (PID=258) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:16:20.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:16:20.558+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:16:20.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:16:20.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:16:20.613+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:16:20.612+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:16:20.641+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:16:20.641+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:16:20.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.126 seconds
[2025-03-15T21:16:51.508+0000] {processor.py:157} INFO - Started process (PID=268) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:16:51.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:16:51.510+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:16:51.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:16:51.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:16:51.562+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:16:51.562+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:16:51.589+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:16:51.589+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:16:51.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.116 seconds
[2025-03-15T21:17:22.449+0000] {processor.py:157} INFO - Started process (PID=278) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:17:22.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:17:22.452+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:17:22.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:17:22.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:17:22.531+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:17:22.531+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:17:22.584+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:17:22.583+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:17:22.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.179 seconds
[2025-03-15T21:17:53.553+0000] {processor.py:157} INFO - Started process (PID=288) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:17:53.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:17:53.557+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:17:53.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:17:53.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:17:53.620+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:17:53.620+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:17:53.644+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:17:53.644+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:17:53.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.124 seconds
[2025-03-15T21:18:24.038+0000] {processor.py:157} INFO - Started process (PID=298) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:18:24.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:18:24.041+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:18:24.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:18:24.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:18:24.095+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:18:24.095+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:18:24.120+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:18:24.120+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:18:24.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.113 seconds
[2025-03-15T21:18:54.988+0000] {processor.py:157} INFO - Started process (PID=308) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:18:54.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:18:54.992+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:18:54.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:18:55.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:18:55.070+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:18:55.070+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:18:55.111+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:18:55.111+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:18:55.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.171 seconds
[2025-03-15T21:19:25.843+0000] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:25.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:19:25.848+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:25.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:25.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:25.931+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:25.930+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:19:25.966+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:25.966+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:19:25.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.157 seconds
[2025-03-15T21:19:27.098+0000] {processor.py:157} INFO - Started process (PID=323) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:19:27.100+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.322+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.322+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:19:27.357+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.357+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:19:27.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.299 seconds
[2025-03-15T21:19:27.446+0000] {processor.py:157} INFO - Started process (PID=328) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:19:27.449+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.506+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.506+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:19:27.544+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.544+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:19:27.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.131 seconds
[2025-03-15T21:19:27.621+0000] {processor.py:157} INFO - Started process (PID=333) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:19:27.623+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.664+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.664+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:19:27.713+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.713+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:19:27.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.127 seconds
[2025-03-15T21:19:27.791+0000] {processor.py:157} INFO - Started process (PID=338) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:19:27.794+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.839+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.839+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:19:27.873+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.872+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:19:27.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.117 seconds
[2025-03-15T21:19:27.955+0000] {processor.py:157} INFO - Started process (PID=343) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:19:27.958+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:27.994+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:27.994+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:19:28.020+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:28.020+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:19:28.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.097 seconds
[2025-03-15T21:19:28.104+0000] {processor.py:157} INFO - Started process (PID=348) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:28.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:19:28.107+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:28.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:28.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:28.159+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:28.159+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:19:28.185+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:28.185+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:19:28.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.113 seconds
[2025-03-15T21:19:59.003+0000] {processor.py:157} INFO - Started process (PID=358) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:59.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:19:59.006+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:59.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:59.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:19:59.064+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:59.064+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:19:59.093+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:19:59.093+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:19:59.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.125 seconds
[2025-03-15T21:20:29.909+0000] {processor.py:157} INFO - Started process (PID=368) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:20:29.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:20:29.912+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:20:29.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:20:29.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:20:30.051+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:20:30.050+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:20:30.150+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:20:30.150+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:20:30.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.294 seconds
[2025-03-15T21:21:00.828+0000] {processor.py:157} INFO - Started process (PID=378) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:00.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:21:00.832+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:00.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:00.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['csv_to_hdfs_ingestion']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:00.921+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:00.920+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:21:00.967+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:00.967+0000] {dag.py:3677} INFO - Setting next_dagrun for csv_to_hdfs_ingestion to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:21:01.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.179 seconds
[2025-03-15T21:21:19.640+0000] {processor.py:157} INFO - Started process (PID=383) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:19.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:21:19.646+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:19.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:19.698+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:19.691+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:21:19.700+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:19.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.123 seconds
[2025-03-15T21:21:19.797+0000] {processor.py:157} INFO - Started process (PID=388) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:19.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:21:19.800+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:19.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:19.820+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:19.815+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:21:19.822+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:19.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.062 seconds
[2025-03-15T21:21:19.910+0000] {processor.py:157} INFO - Started process (PID=393) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:19.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:21:19.913+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:19.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:19.949+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:19.941+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:21:19.952+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:19.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.092 seconds
[2025-03-15T21:21:20.050+0000] {processor.py:157} INFO - Started process (PID=398) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:21:20.053+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:20.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.072+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:20.067+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:21:20.074+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.055 seconds
[2025-03-15T21:21:20.151+0000] {processor.py:157} INFO - Started process (PID=403) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:21:20.153+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:20.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.176+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:20.171+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:21:20.179+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T21:21:20.276+0000] {processor.py:157} INFO - Started process (PID=408) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:21:20.279+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:20.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.305+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:20.301+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:21:20.306+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.066 seconds
[2025-03-15T21:21:20.400+0000] {processor.py:157} INFO - Started process (PID=413) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:21:20.404+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:20.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.433+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:20.425+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:21:20.434+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:20.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.068 seconds
[2025-03-15T21:21:51.330+0000] {processor.py:157} INFO - Started process (PID=423) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:51.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:21:51.332+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:51.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:51.346+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:21:51.343+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:21:51.347+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:21:51.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.043 seconds
[2025-03-15T21:22:22.162+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:22:22.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:22:22.164+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:22:22.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:22:22.179+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:22:22.175+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:22:22.180+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:22:22.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.057 seconds
[2025-03-15T21:22:53.223+0000] {processor.py:157} INFO - Started process (PID=443) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:22:53.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:22:53.232+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:22:53.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:22:53.347+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:22:53.334+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:22:53.351+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:22:53.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.247 seconds
[2025-03-15T21:23:24.276+0000] {processor.py:157} INFO - Started process (PID=453) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:23:24.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:23:24.280+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:23:24.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:23:24.300+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:23:24.295+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:23:24.301+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:23:24.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T21:23:55.124+0000] {processor.py:157} INFO - Started process (PID=463) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:23:55.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:23:55.136+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:23:55.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:23:55.183+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:23:55.171+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:23:55.188+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:23:55.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.146 seconds
[2025-03-15T21:24:25.393+0000] {processor.py:157} INFO - Started process (PID=473) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:24:25.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:24:25.397+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:24:25.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:24:25.421+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:24:25.416+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:24:25.423+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:24:25.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.064 seconds
[2025-03-15T21:24:55.973+0000] {processor.py:157} INFO - Started process (PID=483) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:24:55.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:24:55.975+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:24:55.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:24:55.997+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:24:55.991+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:24:55.999+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:24:56.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.055 seconds
[2025-03-15T21:25:27.083+0000] {processor.py:157} INFO - Started process (PID=493) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:25:27.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:25:27.086+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:25:27.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:25:27.112+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:25:27.105+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:25:27.115+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:25:27.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.078 seconds
[2025-03-15T21:25:57.965+0000] {processor.py:157} INFO - Started process (PID=503) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:25:57.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:25:57.967+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:25:57.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:25:57.981+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:25:57.978+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:25:57.982+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:25:58.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.059 seconds
[2025-03-15T21:26:28.359+0000] {processor.py:157} INFO - Started process (PID=513) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:26:28.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:26:28.362+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:26:28.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:26:28.376+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:26:28.373+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:26:28.377+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:26:28.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.058 seconds
[2025-03-15T21:26:59.326+0000] {processor.py:157} INFO - Started process (PID=523) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:26:59.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:26:59.329+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:26:59.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:26:59.349+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:26:59.345+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:26:59.351+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:26:59.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.056 seconds
[2025-03-15T21:27:29.579+0000] {processor.py:157} INFO - Started process (PID=533) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:27:29.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:27:29.588+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:27:29.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:27:29.629+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:27:29.623+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/ingestion.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/ingestion.py", line 25, in <module>
    dag = DAG(
NameError: name 'DAG' is not defined
[2025-03-15T21:27:29.631+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:27:29.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.123 seconds
[2025-03-15T21:27:42.125+0000] {processor.py:157} INFO - Started process (PID=543) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:27:42.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:27:42.131+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:27:42.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:27:43.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_crypto_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:27:44.133+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:27:44.133+0000] {manager.py:501} INFO - Created Permission View: can edit on DAG:fetch_crypto_data_and_upload_to_hdfs
[2025-03-15T21:27:44.155+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:27:44.155+0000] {manager.py:501} INFO - Created Permission View: can delete on DAG:fetch_crypto_data_and_upload_to_hdfs
[2025-03-15T21:27:44.191+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:27:44.191+0000] {manager.py:501} INFO - Created Permission View: can read on DAG:fetch_crypto_data_and_upload_to_hdfs
[2025-03-15T21:27:44.231+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:27:44.229+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:27:44.256+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:27:44.255+0000] {dag.py:2929} INFO - Creating ORM DAG for fetch_crypto_data_and_upload_to_hdfs
[2025-03-15T21:27:44.278+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:27:44.278+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_crypto_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:27:44.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 2.190 seconds
[2025-03-15T21:28:15.205+0000] {processor.py:157} INFO - Started process (PID=554) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:28:15.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:28:15.207+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:28:15.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:28:15.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_crypto_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:28:15.634+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:28:15.633+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:28:15.676+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:28:15.675+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_crypto_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:28:15.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.524 seconds
[2025-03-15T21:28:46.606+0000] {processor.py:157} INFO - Started process (PID=565) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:28:46.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:28:46.609+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:28:46.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:28:47.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_crypto_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:28:47.034+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:28:47.033+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:28:47.069+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:28:47.069+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_crypto_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:28:47.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.506 seconds
[2025-03-15T21:29:17.553+0000] {processor.py:157} INFO - Started process (PID=576) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:29:17.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:29:17.556+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:29:17.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:29:18.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_crypto_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:29:18.098+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:29:18.097+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:29:18.136+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:29:18.135+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_crypto_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:29:18.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.666 seconds
[2025-03-15T21:29:49.063+0000] {processor.py:157} INFO - Started process (PID=587) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:29:49.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:29:49.066+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:29:49.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:29:49.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_crypto_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:29:49.491+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:29:49.490+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:29:49.524+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:29:49.524+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_crypto_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:29:49.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.491 seconds
[2025-03-15T21:30:20.381+0000] {processor.py:157} INFO - Started process (PID=598) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:30:20.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:30:20.390+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:30:20.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:30:20.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_crypto_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:30:20.965+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:30:20.965+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:30:21.004+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:30:21.004+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_crypto_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:30:21.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.661 seconds
[2025-03-15T21:30:51.307+0000] {processor.py:157} INFO - Started process (PID=609) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:30:51.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:30:51.311+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:30:51.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:30:52.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_crypto_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:30:52.221+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:30:52.220+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:30:52.274+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:30:52.273+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_crypto_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:30:52.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 1.016 seconds
[2025-03-15T21:31:23.244+0000] {processor.py:157} INFO - Started process (PID=620) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:31:23.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:31:23.246+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:31:23.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:31:23.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_crypto_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:31:23.726+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:31:23.726+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:31:23.766+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:31:23.766+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_crypto_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:31:23.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.559 seconds
[2025-03-15T21:31:38.131+0000] {processor.py:157} INFO - Started process (PID=631) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:31:38.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:31:38.134+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:31:38.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:31:38.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:31:39.068+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:31:39.068+0000] {manager.py:501} INFO - Created Permission View: can edit on DAG:fetch_transaction_data_and_upload_to_hdfs
[2025-03-15T21:31:39.084+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:31:39.084+0000] {manager.py:501} INFO - Created Permission View: can delete on DAG:fetch_transaction_data_and_upload_to_hdfs
[2025-03-15T21:31:39.093+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:31:39.093+0000] {manager.py:501} INFO - Created Permission View: can read on DAG:fetch_transaction_data_and_upload_to_hdfs
[2025-03-15T21:31:39.131+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:31:39.130+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:31:39.207+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:31:39.206+0000] {dag.py:2929} INFO - Creating ORM DAG for fetch_transaction_data_and_upload_to_hdfs
[2025-03-15T21:31:39.256+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:31:39.256+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:31:39.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 1.169 seconds
[2025-03-15T21:32:10.157+0000] {processor.py:157} INFO - Started process (PID=642) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:32:10.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:32:10.160+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:32:10.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:32:10.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:32:10.800+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:32:10.799+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:32:10.842+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:32:10.842+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T21:32:10.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.719 seconds
[2025-03-15T21:32:41.096+0000] {processor.py:157} INFO - Started process (PID=659) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:32:41.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:32:41.098+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:32:41.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:32:41.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:32:41.608+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:32:41.607+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:32:41.638+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:32:41.638+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:32:41.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.574 seconds
[2025-03-15T21:33:12.442+0000] {processor.py:157} INFO - Started process (PID=670) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:33:12.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:33:12.446+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:33:12.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:33:12.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:33:12.919+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:33:12.918+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:33:12.953+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:33:12.953+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:33:12.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.550 seconds
[2025-03-15T21:33:43.361+0000] {processor.py:157} INFO - Started process (PID=681) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:33:43.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:33:43.366+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:33:43.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:33:43.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:33:43.807+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:33:43.807+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:33:43.841+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:33:43.840+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:33:43.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.513 seconds
[2025-03-15T21:34:14.760+0000] {processor.py:157} INFO - Started process (PID=692) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:34:14.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:34:14.764+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:34:14.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:34:15.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:34:15.273+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:34:15.272+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:34:15.301+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:34:15.301+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:34:15.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.580 seconds
[2025-03-15T21:34:46.220+0000] {processor.py:157} INFO - Started process (PID=703) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:34:46.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:34:46.226+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:34:46.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:34:46.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:34:46.701+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:34:46.700+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:34:46.729+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:34:46.728+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:34:46.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.551 seconds
[2025-03-15T21:35:17.561+0000] {processor.py:157} INFO - Started process (PID=714) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:35:17.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:35:17.563+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:35:17.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:35:17.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:35:17.966+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:35:17.965+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:35:17.990+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:35:17.990+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:35:18.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.458 seconds
[2025-03-15T21:35:48.839+0000] {processor.py:157} INFO - Started process (PID=725) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:35:48.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:35:48.844+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:35:48.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:35:49.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:35:49.293+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:35:49.292+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:35:49.328+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:35:49.328+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:35:49.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.524 seconds
[2025-03-15T21:36:19.574+0000] {processor.py:157} INFO - Started process (PID=736) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:36:19.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:36:19.578+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:36:19.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:36:20.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:36:20.085+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:36:20.084+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:36:20.114+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:36:20.114+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:36:20.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.573 seconds
[2025-03-15T21:36:50.416+0000] {processor.py:157} INFO - Started process (PID=747) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:36:50.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:36:50.419+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:36:50.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:36:50.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:36:50.780+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:36:50.780+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:36:50.813+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:36:50.813+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:36:50.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.428 seconds
[2025-03-15T21:37:21.071+0000] {processor.py:157} INFO - Started process (PID=758) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:37:21.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:37:21.073+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:37:21.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:37:21.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:37:21.408+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:37:21.407+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:37:21.433+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:37:21.433+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:37:21.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.389 seconds
[2025-03-15T21:37:51.870+0000] {processor.py:157} INFO - Started process (PID=775) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:37:51.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:37:51.873+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:37:51.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:37:52.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:37:52.329+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:37:52.329+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:37:52.353+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:37:52.353+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:37:52.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.509 seconds
[2025-03-15T21:38:22.962+0000] {processor.py:157} INFO - Started process (PID=786) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:38:22.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:38:22.966+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:38:22.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:38:23.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:38:23.324+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:38:23.324+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:38:23.346+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:38:23.345+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:38:23.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.418 seconds
[2025-03-15T21:38:53.558+0000] {processor.py:157} INFO - Started process (PID=797) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:38:53.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:38:53.560+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:38:53.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:38:54.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:38:54.071+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:38:54.070+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:38:54.136+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:38:54.136+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:38:54.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.622 seconds
[2025-03-15T21:39:24.765+0000] {processor.py:157} INFO - Started process (PID=808) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:39:24.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:39:24.769+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:39:24.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:39:25.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:39:25.248+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:39:25.247+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:39:25.279+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:39:25.279+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:39:25.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.544 seconds
[2025-03-15T21:39:56.253+0000] {processor.py:157} INFO - Started process (PID=819) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T21:39:56.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T21:39:56.256+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:39:56.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T21:39:56.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T21:39:56.678+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:39:56.678+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T21:39:56.717+0000] {logging_mixin.py:151} INFO - [2025-03-15T21:39:56.717+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-15T00:00:00+00:00, run_after=2025-03-16T00:00:00+00:00
[2025-03-15T21:39:56.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.503 seconds
[2025-03-15T22:11:11.907+0000] {processor.py:157} INFO - Started process (PID=164) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:11:11.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:11:11.916+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:11:11.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:11:15.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:11:15.775+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:11:15.774+0000] {manager.py:501} INFO - Created Permission View: can read on DAG:fetch_transaction_data_and_upload_to_hdfs
[2025-03-15T22:11:15.795+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:11:15.794+0000] {manager.py:501} INFO - Created Permission View: can delete on DAG:fetch_transaction_data_and_upload_to_hdfs
[2025-03-15T22:11:15.806+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:11:15.806+0000] {manager.py:501} INFO - Created Permission View: can edit on DAG:fetch_transaction_data_and_upload_to_hdfs
[2025-03-15T22:11:15.829+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:11:15.828+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:11:15.847+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:11:15.846+0000] {dag.py:2929} INFO - Creating ORM DAG for fetch_transaction_data_and_upload_to_hdfs
[2025-03-15T22:11:15.866+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:11:15.866+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:11:15.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 4.018 seconds
[2025-03-15T22:11:45.972+0000] {processor.py:157} INFO - Started process (PID=180) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:11:45.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:11:45.974+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:11:45.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:11:46.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:11:46.495+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:11:46.495+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:11:46.516+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:11:46.516+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:11:46.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.565 seconds
[2025-03-15T22:12:17.403+0000] {processor.py:157} INFO - Started process (PID=191) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:12:17.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:12:17.407+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:12:17.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:12:18.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:12:18.256+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:12:18.255+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:12:18.290+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:12:18.289+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:12:18.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.916 seconds
[2025-03-15T22:12:48.383+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:12:48.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:12:48.385+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:12:48.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:12:48.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:12:48.975+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:12:48.975+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:12:49.002+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:12:49.002+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:12:49.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.650 seconds
[2025-03-15T22:13:19.579+0000] {processor.py:157} INFO - Started process (PID=213) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:13:19.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:13:19.582+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:13:19.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:13:20.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:13:20.160+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:13:20.159+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:13:20.187+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:13:20.187+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:13:20.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.638 seconds
[2025-03-15T22:13:50.475+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:13:50.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:13:50.477+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:13:50.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:13:50.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:13:50.988+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:13:50.988+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:13:51.011+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:13:51.011+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:13:51.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.564 seconds
[2025-03-15T22:14:21.756+0000] {processor.py:157} INFO - Started process (PID=235) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:14:21.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:14:21.759+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:14:21.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:14:22.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:14:22.345+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:14:22.345+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:14:22.367+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:14:22.367+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:14:22.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.633 seconds
[2025-03-15T22:14:53.092+0000] {processor.py:157} INFO - Started process (PID=246) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:14:53.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:14:53.098+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:14:53.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:14:53.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:14:53.891+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:14:53.891+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:14:53.918+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:14:53.918+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:14:53.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.862 seconds
[2025-03-15T22:15:24.340+0000] {processor.py:157} INFO - Started process (PID=263) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:15:24.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:15:24.343+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:15:24.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:15:24.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:15:24.839+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:15:24.838+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:15:24.866+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:15:24.865+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:15:24.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.552 seconds
[2025-03-15T22:15:55.570+0000] {processor.py:157} INFO - Started process (PID=277) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:15:55.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:15:55.574+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:15:55.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:15:55.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:15:56.002+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:15:56.001+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:15:56.031+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:15:56.031+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:15:56.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.492 seconds
[2025-03-15T22:16:26.916+0000] {processor.py:157} INFO - Started process (PID=288) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:16:26.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:16:26.921+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:16:26.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:16:27.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:16:27.437+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:16:27.436+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:16:27.461+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:16:27.461+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:16:27.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.578 seconds
[2025-03-15T22:16:56.331+0000] {processor.py:157} INFO - Started process (PID=299) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:16:56.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:16:56.333+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:16:56.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:16:56.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:16:56.715+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:16:56.714+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:16:56.763+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:16:56.763+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:16:56.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.469 seconds
[2025-03-15T22:17:27.171+0000] {processor.py:157} INFO - Started process (PID=310) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:17:27.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:17:27.173+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:17:27.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:17:27.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:17:27.502+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:17:27.501+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:17:27.523+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:17:27.523+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:17:27.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.380 seconds
[2025-03-15T22:17:58.353+0000] {processor.py:157} INFO - Started process (PID=321) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:17:58.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:17:58.355+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:17:58.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T22:17:58.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T22:17:58.691+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:17:58.691+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T22:17:58.728+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:17:58.728+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T22:17:58.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.403 seconds
[2025-03-15T22:30:06.119+0000] {processor.py:157} INFO - Started process (PID=327) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T22:30:06.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T22:30:06.122+0000] {logging_mixin.py:151} INFO - [2025-03-15T22:30:06.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:45:03.029+0000] {processor.py:157} INFO - Started process (PID=338) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:45:03.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:45:03.034+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:45:03.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:45:03.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:45:03.922+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:45:03.922+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:45:03.970+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:45:03.969+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:45:04.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.983 seconds
[2025-03-15T23:45:34.589+0000] {processor.py:157} INFO - Started process (PID=354) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:45:34.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:45:34.592+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:45:34.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:45:35.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:45:35.146+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:45:35.145+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:45:35.193+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:45:35.192+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:45:35.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.652 seconds
[2025-03-15T23:46:05.751+0000] {processor.py:157} INFO - Started process (PID=365) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:46:05.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:46:05.754+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:46:05.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:46:06.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:46:06.119+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:46:06.118+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:46:06.144+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:46:06.144+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:46:06.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.417 seconds
[2025-03-15T23:46:36.897+0000] {processor.py:157} INFO - Started process (PID=376) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:46:36.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:46:36.900+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:46:36.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:46:37.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:46:37.293+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:46:37.293+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:46:37.322+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:46:37.322+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:46:37.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.459 seconds
[2025-03-15T23:47:08.147+0000] {processor.py:157} INFO - Started process (PID=387) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:47:08.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:47:08.149+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:47:08.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:47:08.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:47:08.486+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:47:08.486+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:47:08.511+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:47:08.511+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:47:08.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.389 seconds
[2025-03-15T23:47:39.213+0000] {processor.py:157} INFO - Started process (PID=398) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:47:39.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:47:39.215+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:47:39.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:47:39.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:47:39.587+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:47:39.586+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:47:39.625+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:47:39.625+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:47:39.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.443 seconds
[2025-03-15T23:48:10.528+0000] {processor.py:157} INFO - Started process (PID=409) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:48:10.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:48:10.530+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:48:10.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:48:10.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:48:10.882+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:48:10.882+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:48:10.914+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:48:10.914+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:48:10.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.425 seconds
[2025-03-15T23:48:41.848+0000] {processor.py:157} INFO - Started process (PID=420) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:48:41.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:48:41.851+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:48:41.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:48:42.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:48:42.220+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:48:42.219+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:48:42.245+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:48:42.244+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:48:42.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.418 seconds
[2025-03-15T23:49:13.114+0000] {processor.py:157} INFO - Started process (PID=431) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:49:13.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:49:13.116+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:49:13.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:49:13.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:49:13.537+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:49:13.537+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:49:13.567+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:49:13.566+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:49:13.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.483 seconds
[2025-03-15T23:49:44.405+0000] {processor.py:157} INFO - Started process (PID=442) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:49:44.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:49:44.407+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:49:44.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:49:44.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:49:44.753+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:49:44.752+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:49:44.783+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:49:44.783+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:49:44.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.406 seconds
[2025-03-15T23:50:15.619+0000] {processor.py:157} INFO - Started process (PID=453) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:50:15.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:50:15.622+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:50:15.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:50:15.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:50:15.950+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:50:15.949+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:50:15.972+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:50:15.972+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:50:15.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.376 seconds
[2025-03-15T23:50:46.077+0000] {processor.py:157} INFO - Started process (PID=464) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:50:46.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:50:46.079+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:50:46.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:50:46.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:50:46.410+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:50:46.409+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:50:46.435+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:50:46.435+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:50:46.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.382 seconds
[2025-03-15T23:51:17.103+0000] {processor.py:157} INFO - Started process (PID=475) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:51:17.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:51:17.107+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:51:17.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:51:17.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:51:17.466+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:51:17.465+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:51:17.494+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:51:17.494+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:51:17.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.419 seconds
[2025-03-15T23:51:48.386+0000] {processor.py:157} INFO - Started process (PID=486) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:51:48.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:51:48.389+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:51:48.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:51:48.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:51:48.763+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:51:48.763+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:51:48.793+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:51:48.793+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:51:48.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.436 seconds
[2025-03-15T23:52:19.579+0000] {processor.py:157} INFO - Started process (PID=497) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:52:19.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:52:19.582+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:52:19.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:52:19.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:52:19.941+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:52:19.941+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:52:19.966+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:52:19.966+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:52:19.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.411 seconds
[2025-03-15T23:52:50.792+0000] {processor.py:157} INFO - Started process (PID=508) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:52:50.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:52:50.796+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:52:50.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:52:51.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:52:51.168+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:52:51.168+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:52:51.189+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:52:51.188+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:52:51.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.423 seconds
[2025-03-15T23:53:22.054+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:53:22.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:53:22.057+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:53:22.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:53:22.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:53:22.420+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:53:22.420+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:53:22.445+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:53:22.445+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:53:22.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.419 seconds
[2025-03-15T23:53:53.276+0000] {processor.py:157} INFO - Started process (PID=530) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:53:53.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:53:53.278+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:53:53.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:53:53.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:53:53.620+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:53:53.619+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:53:53.646+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:53:53.645+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:53:53.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.393 seconds
[2025-03-15T23:54:24.470+0000] {processor.py:157} INFO - Started process (PID=541) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:54:24.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:54:24.474+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:54:24.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:54:24.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:54:24.852+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:54:24.851+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:54:24.879+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:54:24.879+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:54:24.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.438 seconds
[2025-03-15T23:54:55.629+0000] {processor.py:157} INFO - Started process (PID=552) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:54:55.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:54:55.631+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:54:55.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:54:56.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:54:56.060+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:54:56.059+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:54:56.087+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:54:56.086+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:54:56.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.485 seconds
[2025-03-15T23:55:26.575+0000] {processor.py:157} INFO - Started process (PID=563) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:55:26.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:55:26.578+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:55:26.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:55:26.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:55:26.949+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:55:26.949+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:55:26.971+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:55:26.971+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:55:26.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.418 seconds
[2025-03-15T23:55:57.714+0000] {processor.py:157} INFO - Started process (PID=574) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:55:57.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:55:57.718+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:55:57.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:55:58.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:55:58.063+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:55:58.063+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:55:58.086+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:55:58.086+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:55:58.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.400 seconds
[2025-03-15T23:56:28.318+0000] {processor.py:157} INFO - Started process (PID=585) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:56:28.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:56:28.323+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:56:28.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:56:28.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:56:28.678+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:56:28.678+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:56:28.700+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:56:28.700+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:56:28.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.411 seconds
[2025-03-15T23:56:59.553+0000] {processor.py:157} INFO - Started process (PID=596) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:56:59.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:56:59.556+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:56:59.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:56:59.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:56:59.969+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:56:59.968+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:57:00.001+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:57:00.001+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:57:00.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.482 seconds
[2025-03-15T23:57:30.715+0000] {processor.py:157} INFO - Started process (PID=607) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:57:30.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:57:30.718+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:57:30.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:57:31.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:57:31.073+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:57:31.073+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:57:31.101+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:57:31.101+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:57:31.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.415 seconds
[2025-03-15T23:58:01.868+0000] {processor.py:157} INFO - Started process (PID=618) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:58:01.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:58:01.872+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:58:01.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:58:02.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:58:02.283+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:58:02.283+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:58:02.312+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:58:02.311+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:58:02.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.475 seconds
[2025-03-15T23:58:33.029+0000] {processor.py:157} INFO - Started process (PID=629) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:58:33.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:58:33.032+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:58:33.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:58:33.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:58:33.403+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:58:33.402+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:58:33.426+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:58:33.426+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:58:33.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.423 seconds
[2025-03-15T23:59:04.031+0000] {processor.py:157} INFO - Started process (PID=640) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:59:04.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:59:04.033+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:59:04.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:59:04.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:59:04.403+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:59:04.403+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:59:04.430+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:59:04.430+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:59:04.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.430 seconds
[2025-03-15T23:59:34.730+0000] {processor.py:157} INFO - Started process (PID=651) to work on /opt/airflow/dags/ingestion.py
[2025-03-15T23:59:34.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/ingestion.py for tasks to queue
[2025-03-15T23:59:34.732+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:59:34.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/ingestion.py
[2025-03-15T23:59:35.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['fetch_transaction_data_and_upload_to_hdfs']) retrieved from /opt/airflow/dags/ingestion.py
[2025-03-15T23:59:34.966+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:59:34.963+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-03-15T23:59:34.996+0000] {logging_mixin.py:151} INFO - [2025-03-15T23:59:34.996+0000] {dag.py:3677} INFO - Setting next_dagrun for fetch_transaction_data_and_upload_to_hdfs to 2025-03-14T00:00:00+00:00, run_after=2025-03-15T00:00:00+00:00
[2025-03-15T23:59:35.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingestion.py took 0.446 seconds
